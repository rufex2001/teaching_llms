{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Methods in Text Analytics\n",
    "# Exercise 8: LLMs - Part 2\n",
    "### Daniel Ruffinelli\n",
    "## FSS 2025\n",
    "\n",
    "* This notebook is designed so we can test basic functions of LLMs in CPU using a regular laptop. For that reason, we stick to small models. But if you have better resources, feel free to modify this to any model that is [available in HuggingFace](https://huggingface.co/models).  \n",
    "* You run this code, you will need to install HuggingFace's [transformers](https://huggingface.co/docs/transformers/en/installation) and [PyTorch](https://pytorch.org/).\n",
    "* You will also need to do the following three things:\n",
    "1. Create a user name in HuggingFace.\n",
    "2. Request access to the following models: [Llama-3.1-1B](https://huggingface.co/meta-llama/Llama-3.2-1B) and [Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct).\n",
    "3. Create an access token, see [here](https://huggingface.co/docs/hub/security-tokens) for instructions. Your access token will be shown to you only once, so make you you copy it somewhere safe, because you will need to use it to login to HuggingFace via this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF login\n",
    "from huggingface_hub import notebook_login\n",
    "access_token = \"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\"\n",
    "\n",
    "# then run this and enter your token (requires ipywidgets) \n",
    "# alternatively, do it via CLI with huggingface-cli login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, we'll store models and their corresponding tokenizers in a \n",
    "# dict of the form {model_name: [model, tokenizer]}\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "models_dict = ddict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set up some constants for convenience\n",
    "DEVICE=\"cpu\"\n",
    "MODEL = 0\n",
    "TOKENIZER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/druffine/postdoc/teaching/advanced_text_analytics/2025_fss/tutorials/08_llms_part_2/llm_basics/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# see all available models in HF here: https://huggingface.co/models\n",
    "# first time you load a model, it will be downloaded, which will take several\n",
    "# minutes, but after that, it will be read from a local cache, so it will be \n",
    "# only a few seconds\n",
    "\n",
    "# we load Llama-3.2-1B \n",
    "llama_name = \"meta-llama/Llama-3.2-1B\"\n",
    "models_dict[\"llama\"].append(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        llama_name, \n",
    "        device_map=DEVICE, \n",
    "        torch_dtype=torch.bfloat16, \n",
    "    )\n",
    ")\n",
    "models_dict[\"llama\"].append(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        llama_name, padding_side=\"left\"\n",
    "        )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load a model similar to GPT-3 made by EleutherAI\n",
    "gpt3_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "models_dict[\"gpt3\"].append(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        gpt3_name, \n",
    "        device_map=DEVICE, \n",
    "        torch_dtype=torch.bfloat16, \n",
    "    )\n",
    ")\n",
    "models_dict[\"gpt3\"].append(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        gpt3_name, padding_side=\"left\"\n",
    "        )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama\n",
      "Model: LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n",
      "\n",
      "Model: gpt3\n",
      "Model: GPTNeoForCausalLM(\n",
      "  (transformer): GPTNeoModel(\n",
      "    (wte): Embedding(50257, 2048)\n",
      "    (wpe): Embedding(2048, 2048)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPTNeoBlock(\n",
      "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPTNeoAttention(\n",
      "          (attention): GPTNeoSelfAttention(\n",
      "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPTNeoMLP(\n",
      "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=50257, bias=False)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see loaded models\n",
    "for model_name, model in models_dict.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Model: {model[MODEL]}\")\n",
    "    # print(f\"Tokenizer: {model[TOKENIZER]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model and tokenizer to use\n",
    "model_name = \"gpt3\"\n",
    "# model_name = \"llama\"\n",
    "# model_name = \"llama_instruct\"\n",
    "model = models_dict[model_name][MODEL]\n",
    "tokenizer = models_dict[model_name][TOKENIZER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[15496,     0]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# set toy prompt\n",
    "prompt = \"\"\"Hello!\"\"\"\n",
    "\n",
    "# tokenize it \n",
    "tokenized_prompt = tokenizer(\n",
    "    prompt, \n",
    "    return_tensors=\"pt\"\n",
    ").to(DEVICE)\n",
    "print(tokenized_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "input_ids:\n",
      "tensor([[15496,     0]])\n",
      "input_ids type: <class 'torch.Tensor'>\n",
      "input_ids size: torch.Size([1, 2])\n",
      "\n",
      "attention_mask:\n",
      "tensor([[1, 1]])\n",
      "attention_mask type: <class 'torch.Tensor'>\n",
      "attention_mask size: torch.Size([1, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### SOLUTION\n",
    "print(type(tokenized_prompt))\n",
    "for key, value in tokenized_prompt.items():\n",
    "    print(f\"{key}:\\n{value}\")\n",
    "    print(f\"{key} type: {type(value)}\")\n",
    "    print(f\"{key} size: {value.size()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CausalLMOutputWithPast(loss=None, logits=tensor([[[  1.6875,  -3.2969,  -7.0312,  ..., -13.8125, -12.2500,  -4.6875],\n",
      "         [ -7.3750,  -9.6250,  -9.0625,  ..., -17.6250, -15.9375,  -5.6562]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-0.2578,  0.1104,  0.2695,  ..., -0.0645,  0.3184,  0.3848],\n",
      "          [-0.3594,  0.5938, -0.1689,  ...,  0.2520,  0.8398,  0.3164]],\n",
      "\n",
      "         [[-0.1777,  0.1562, -0.5586,  ...,  0.3379, -0.0262,  0.0486],\n",
      "          [-0.0776,  0.0996, -0.2500,  ..., -0.0349, -0.3047, -0.2324]],\n",
      "\n",
      "         [[ 0.5352, -0.5859,  0.1748,  ..., -0.3926, -0.0332,  0.2441],\n",
      "          [ 0.6445, -0.3965,  0.2617,  ..., -0.3320,  0.1611,  0.0972]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4121,  0.2178, -0.0913,  ..., -1.9141, -0.7852,  0.0349],\n",
      "          [-0.2598, -0.1196, -0.2285,  ..., -1.7266, -0.6719, -0.2656]],\n",
      "\n",
      "         [[-0.9844,  0.3320, -0.0281,  ..., -0.3965,  0.2695,  0.5625],\n",
      "          [-1.1328,  0.2617,  0.4785,  ..., -0.1748, -0.0737,  0.0322]],\n",
      "\n",
      "         [[ 0.5391,  0.0442, -0.0742,  ...,  0.6016, -0.0483,  0.1348],\n",
      "          [ 1.0547, -0.4746,  0.0435,  ...,  0.6602, -0.0039, -0.7812]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-1.4844e-01, -4.1016e-01, -2.2949e-02,  ...,  1.8750e-01,\n",
      "           -7.2754e-02,  1.6211e-01],\n",
      "          [ 3.7598e-02,  1.2500e-01, -2.5000e-01,  ...,  6.2256e-02,\n",
      "            3.8818e-02, -4.1016e-01]],\n",
      "\n",
      "         [[-8.6914e-02, -1.0596e-01, -4.8340e-02,  ...,  1.8945e-01,\n",
      "           -3.3594e-01,  4.4678e-02],\n",
      "          [ 5.5469e-01,  2.5195e-01,  2.7930e-01,  ...,  6.6406e-01,\n",
      "           -2.6758e-01, -3.3203e-01]],\n",
      "\n",
      "         [[ 1.2891e-01,  2.7148e-01, -5.6396e-02,  ...,  8.3008e-03,\n",
      "            7.5684e-02, -2.3242e-01],\n",
      "          [ 8.8867e-02,  1.7676e-01, -1.3672e-01,  ..., -6.4453e-01,\n",
      "            5.3906e-01, -4.7852e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1182e-01,  2.3926e-01,  2.9102e-01,  ...,  1.2012e-01,\n",
      "            1.1328e-01, -1.2891e-01],\n",
      "          [-7.9590e-02, -1.7383e-01, -3.9062e-02,  ..., -5.1562e-01,\n",
      "            9.1797e-02, -1.6968e-02]],\n",
      "\n",
      "         [[ 4.3359e-01, -2.7344e-01,  1.6016e-01,  ...,  3.4766e-01,\n",
      "            9.9121e-02,  1.9453e+00],\n",
      "          [-3.6133e-01, -8.2422e-01, -1.9336e-01,  ..., -5.7031e-01,\n",
      "           -6.8750e-01,  1.7344e+00]],\n",
      "\n",
      "         [[-3.0151e-02, -2.6562e-01,  5.8203e-01,  ..., -2.7734e-01,\n",
      "            6.1417e-04,  5.8984e-01],\n",
      "          [-7.3730e-02,  1.1963e-01,  4.8633e-01,  ..., -2.7148e-01,\n",
      "           -1.9824e-01,  6.6406e-02]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.9570, -0.0884, -0.2031,  ...,  0.5508, -0.7891,  1.7891],\n",
      "          [-0.4551, -0.3164, -0.4102,  ...,  0.3320, -0.9570,  2.1406]],\n",
      "\n",
      "         [[ 1.0000,  1.2266,  0.8203,  ...,  1.1562, -0.0087,  0.0231],\n",
      "          [ 1.5312,  1.4062,  0.8398,  ...,  0.8242,  0.1738, -0.7812]],\n",
      "\n",
      "         [[ 0.3809,  0.7656,  0.8828,  ..., -0.0459,  0.6406,  2.4531],\n",
      "          [-0.0275,  0.6055,  0.3164,  ..., -0.3398,  0.8555,  2.6719]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2109, -1.1719, -0.6289,  ...,  1.4219, -1.2891, -0.6367],\n",
      "          [-1.6875, -1.0781, -0.4805,  ...,  1.8438, -1.6016, -1.0391]],\n",
      "\n",
      "         [[-0.1260,  0.5273, -0.0347,  ...,  0.1807, -0.7344,  0.7344],\n",
      "          [ 0.0525,  0.4434,  0.2754,  ...,  0.4219, -0.5273,  0.9961]],\n",
      "\n",
      "         [[ 0.3770, -0.2295,  0.3398,  ..., -0.7812, -0.0105, -1.0156],\n",
      "          [ 0.6172, -0.7734,  0.1299,  ..., -0.6367, -0.0332, -0.6719]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0977, -0.1108, -0.1040,  ...,  0.0214, -0.1001,  0.0090],\n",
      "          [ 0.2676,  0.0262,  0.0713,  ..., -0.1260, -0.2197,  0.1426]],\n",
      "\n",
      "         [[-0.3281, -0.1807,  0.1855,  ...,  0.0267, -0.0259, -0.0304],\n",
      "          [ 0.2100,  0.1006,  0.0845,  ..., -0.1543,  0.1279, -0.1064]],\n",
      "\n",
      "         [[ 0.4570,  0.2812, -0.1709,  ..., -0.1836,  0.0262, -0.0167],\n",
      "          [ 0.3945,  0.0330,  0.1553,  ...,  0.1270, -0.2383, -0.1650]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0150, -0.0601,  0.0206,  ...,  0.0415, -0.0019,  0.1758],\n",
      "          [-0.0933, -0.0598, -0.1699,  ...,  0.1328, -0.3730, -0.1748]],\n",
      "\n",
      "         [[-0.3633, -0.0381, -0.0231,  ..., -0.2051,  0.1670,  0.0630],\n",
      "          [-0.1982,  0.1426,  0.1729,  ..., -0.3047,  0.0029, -0.0422]],\n",
      "\n",
      "         [[-0.0037,  0.1279, -0.0471,  ...,  0.0850,  0.0312,  0.2559],\n",
      "          [ 0.0199,  0.0228,  0.1240,  ...,  0.4043,  0.0962, -0.3535]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3965e-01, -1.7871e-01, -2.0215e-01,  ...,  4.2578e-01,\n",
      "            8.7891e-01, -2.1973e-01],\n",
      "          [ 1.2012e-01,  1.7871e-01,  1.3965e-01,  ...,  5.4688e-01,\n",
      "            9.4141e-01,  2.5195e-01]],\n",
      "\n",
      "         [[-1.1250e+00, -1.4844e-01, -7.5391e-01,  ..., -9.0234e-01,\n",
      "            8.5938e-02,  2.2949e-01],\n",
      "          [-1.3906e+00, -4.6143e-02, -4.8438e-01,  ..., -7.7734e-01,\n",
      "            1.6016e-01, -1.1108e-02]],\n",
      "\n",
      "         [[-1.7383e-01, -2.0215e-01, -1.4648e-01,  ..., -1.1523e-01,\n",
      "            1.0400e-01,  3.4375e-01],\n",
      "          [-1.7969e-01, -1.9629e-01, -1.0596e-01,  ..., -5.1514e-02,\n",
      "            9.6191e-02,  2.5586e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5182e-03, -1.3281e-01,  1.0986e-01,  ..., -3.6865e-02,\n",
      "           -2.1777e-01, -3.7109e-02],\n",
      "          [ 1.3184e-01, -3.7305e-01,  2.1387e-01,  ..., -5.8594e-02,\n",
      "           -3.8330e-02,  1.4160e-01]],\n",
      "\n",
      "         [[-2.1680e-01, -4.6680e-01, -2.0020e-01,  ..., -2.8320e-01,\n",
      "            4.3701e-02,  4.4141e-01],\n",
      "          [-3.3008e-01, -3.0469e-01, -1.1426e-01,  ..., -7.3242e-04,\n",
      "           -8.1543e-02,  1.5527e-01]],\n",
      "\n",
      "         [[ 9.9609e-01,  5.7812e-01, -5.5078e-01,  ..., -2.2852e-01,\n",
      "            1.7700e-02,  4.3213e-02],\n",
      "          [ 4.5312e-01,  8.3984e-01, -4.3555e-01,  ..., -3.9062e-01,\n",
      "           -1.4954e-02, -2.1680e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.3105,  0.2432,  0.1680,  ..., -0.4648,  0.1514,  0.0088],\n",
      "          [-0.0172,  0.1416, -0.1631,  ...,  0.0479, -0.1885,  0.2910]],\n",
      "\n",
      "         [[-0.1133, -0.1060,  0.0227,  ...,  0.0518,  0.0625, -0.0574],\n",
      "          [ 0.0012,  0.0938, -0.1455,  ..., -0.3145,  0.1045, -0.0168]],\n",
      "\n",
      "         [[ 0.1553, -0.3125, -0.0048,  ..., -0.1221, -0.2314,  0.6172],\n",
      "          [ 0.3223, -0.3770,  0.1465,  ..., -0.2559,  0.2324,  0.6367]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2617,  0.3867,  0.0703,  ...,  0.6133, -0.0708,  0.1689],\n",
      "          [ 0.0420,  0.1602, -0.0435,  ...,  0.6914, -0.1377, -0.2324]],\n",
      "\n",
      "         [[-0.3750, -0.0840, -0.0439,  ..., -0.4238, -0.1777, -0.0398],\n",
      "          [ 0.1475, -0.1758, -0.5078,  ...,  0.2148,  0.4277,  0.0796]],\n",
      "\n",
      "         [[ 0.1670,  0.2139, -0.1533,  ..., -0.3398,  0.2695, -0.0898],\n",
      "          [ 0.5508, -0.2070, -0.0864,  ..., -0.1387,  0.1982,  0.3965]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.1094, -6.0000, -3.7969,  ...,  6.5938, -5.5000,  2.6875],\n",
      "          [ 2.9375, -5.8750, -3.9219,  ...,  6.5000, -5.7812,  2.7188]],\n",
      "\n",
      "         [[-0.0173,  2.8281, -0.3594,  ...,  0.5625,  0.2734, -0.3066],\n",
      "          [-0.2139,  2.4219, -0.1689,  ...,  0.5039,  0.1777, -0.1582]],\n",
      "\n",
      "         [[-1.4219, -0.2148,  5.0625,  ..., -1.7578, -1.0000,  3.9688],\n",
      "          [-1.3594, -0.8789,  5.0625,  ..., -1.5859, -0.8516,  3.7656]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1406,  5.9062, -1.2422,  ...,  3.5938,  1.3203,  1.2266],\n",
      "          [-1.9062,  6.0312, -1.6250,  ...,  3.4688,  1.5156,  1.3359]],\n",
      "\n",
      "         [[ 0.5195,  0.4062, -0.0138,  ...,  0.9180,  0.5547, -0.2891],\n",
      "          [ 0.5273,  0.3867, -0.1611,  ...,  0.9180,  0.4648, -0.3984]],\n",
      "\n",
      "         [[-0.2227, -2.6250,  0.3594,  ..., -0.8359,  4.4062, -1.6172],\n",
      "          [-0.1699, -3.0156, -0.0664,  ..., -0.8203,  4.0938, -1.1094]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.2734, -0.1328, -0.4707,  ...,  0.4043,  0.0200, -0.2969],\n",
      "          [ 0.0933,  0.0308, -0.2949,  ..., -0.0148, -0.0160, -0.2256]],\n",
      "\n",
      "         [[-0.3711, -0.2324,  1.0469,  ..., -0.0713, -0.2021,  0.0540],\n",
      "          [-0.2676, -0.1875,  0.7266,  ...,  0.0381, -0.0986,  0.1318]],\n",
      "\n",
      "         [[ 0.1875, -0.2324,  0.0188,  ...,  0.1299, -0.1748, -0.0042],\n",
      "          [ 0.0623,  0.0903,  0.2734,  ..., -0.0603, -0.1216, -0.1914]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0391,  0.1514, -0.0679,  ..., -0.2832,  0.0034,  0.1807],\n",
      "          [ 0.1377, -0.1855, -0.2949,  ..., -0.1128, -0.0238,  0.0206]],\n",
      "\n",
      "         [[-0.1245, -0.1895, -0.1709,  ...,  0.0201,  0.2891, -0.0271],\n",
      "          [-0.2119, -0.4922, -0.2520,  ...,  0.0684,  0.2480,  0.2656]],\n",
      "\n",
      "         [[ 0.0771, -0.1152, -0.1162,  ..., -0.1758, -0.0435,  0.0845],\n",
      "          [ 0.2754, -0.0830, -0.0703,  ..., -0.0356, -0.1816,  0.0498]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ -0.6562,   1.0391,  -0.3145,  ...,  -0.3828,  -0.1611,  -1.3906],\n",
      "          [ -0.4648,   0.9727,   0.1992,  ...,  -0.6406,  -0.5742,  -1.4219]],\n",
      "\n",
      "         [[  0.7148,   0.7070,  -1.0312,  ...,  -5.5000,  -3.9531,  -5.0938],\n",
      "          [  0.8125,   0.7773,  -1.1641,  ...,  -5.7188,  -4.0938,  -5.5625]],\n",
      "\n",
      "         [[  0.1406,   5.5000,   4.2812,  ...,   1.6953,  -3.5625,   2.4219],\n",
      "          [  0.7461,   5.2188,   4.9688,  ...,   1.3750,  -3.7188,   2.3438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -3.8906,  -0.0723,   4.4062,  ...,   0.3887,  -2.0469,  -2.3594],\n",
      "          [ -3.8750,  -0.2119,   3.9062,  ...,   0.8398,  -2.4062,  -2.4531]],\n",
      "\n",
      "         [[ -0.6875,   1.4219,   2.5469,  ..., -18.0000,   2.4688,   0.9375],\n",
      "          [ -0.7578,   2.0625,   2.6250,  ..., -18.1250,   2.5625,   1.0078]],\n",
      "\n",
      "         [[  6.4375,  -3.7812,   2.1250,  ...,   1.7266,  -0.2197,  -1.3438],\n",
      "          [  6.2500,  -3.9375,   2.4844,  ...,   2.1094,  -0.4082,  -1.3359]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0659,  0.0552, -0.1953,  ..., -0.0981, -0.2041, -0.1973],\n",
      "          [-0.0272,  0.0481,  0.2227,  ..., -0.0918, -0.2070,  0.0251]],\n",
      "\n",
      "         [[ 0.1836,  0.3027,  0.1982,  ..., -0.1641, -0.1924, -0.1602],\n",
      "          [-0.1152, -0.0400, -0.0400,  ..., -0.1338, -0.1030,  0.4531]],\n",
      "\n",
      "         [[-0.0017,  0.1123, -0.1758,  ..., -0.2539,  0.0164,  0.1963],\n",
      "          [-0.1138,  0.1055,  0.3438,  ...,  0.2305,  0.2305, -0.2910]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1855, -0.1348,  0.0664,  ..., -0.1797, -0.3066, -0.0209],\n",
      "          [-0.1641, -0.1035, -0.0503,  ...,  0.2031, -0.2480,  0.3340]],\n",
      "\n",
      "         [[-0.1182, -0.0264,  0.3887,  ...,  0.4434, -0.0114, -0.0967],\n",
      "          [ 0.0344,  0.0022,  0.0679,  ..., -0.0923,  0.6445, -0.0767]],\n",
      "\n",
      "         [[-0.2236,  0.0261,  0.1074,  ..., -0.1533,  0.0835, -0.0114],\n",
      "          [-0.0254, -0.1631,  0.0645,  ...,  0.2422, -0.1514, -0.2051]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5508, -2.7812, -3.7188,  ...,  2.6094,  0.9375, -1.9766],\n",
      "          [-0.5039, -2.8281, -3.6719,  ...,  2.3594,  0.4492, -2.2656]],\n",
      "\n",
      "         [[ 3.2031, -1.2578,  2.2031,  ...,  6.7812,  2.6094, -1.8906],\n",
      "          [ 3.3906, -1.0938,  1.9922,  ...,  7.1875,  2.9219, -1.5781]],\n",
      "\n",
      "         [[ 0.4336,  1.3828,  2.3281,  ..., -1.0156,  2.7031, -2.2344],\n",
      "          [-0.1196,  1.3906,  2.2812,  ..., -0.3965,  2.9688, -2.2344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7695, -0.6445,  4.2812,  ..., -3.6719, -4.9062,  4.5000],\n",
      "          [ 0.9531, -0.6758,  4.5938,  ..., -4.0000, -5.1875,  4.0625]],\n",
      "\n",
      "         [[-1.2344, -0.5391, -2.2969,  ..., -0.3984, -4.8438,  0.1836],\n",
      "          [-0.9141, -0.9609, -2.5156,  ..., -0.6641, -4.8438,  0.2109]],\n",
      "\n",
      "         [[ 0.2080,  6.4375, -0.6172,  ...,  4.7812, -1.5781,  1.1406],\n",
      "          [ 0.2061,  6.9375, -0.2256,  ...,  4.8125, -1.6641,  0.7891]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-1.1670e-01, -2.4316e-01,  5.2002e-02,  ...,  2.9602e-03,\n",
      "            1.9434e-01, -4.6094e-01],\n",
      "          [ 3.7305e-01,  7.5195e-02, -9.3262e-02,  ..., -2.2559e-01,\n",
      "           -4.3945e-01, -7.3730e-02]],\n",
      "\n",
      "         [[-5.6396e-02,  6.3965e-02, -2.3315e-02,  ...,  3.4180e-02,\n",
      "            1.9922e-01,  1.7773e-01],\n",
      "          [ 2.4219e-01, -4.7852e-02, -2.8564e-02,  ...,  3.5889e-02,\n",
      "            2.9688e-01,  2.6733e-02]],\n",
      "\n",
      "         [[-1.2402e-01, -1.1963e-01,  6.6406e-02,  ...,  3.7695e-01,\n",
      "           -1.5747e-02, -1.4062e-01],\n",
      "          [-1.3965e-01, -2.2754e-01, -6.3965e-02,  ..., -2.0703e-01,\n",
      "            2.6562e-01,  1.9434e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6060e-03,  1.8457e-01, -8.7891e-02,  ...,  7.7148e-02,\n",
      "           -7.6172e-02, -2.1973e-01],\n",
      "          [-1.1133e-01, -2.0020e-01, -1.9531e-02,  ...,  1.8066e-01,\n",
      "            9.7656e-03,  2.8516e-01]],\n",
      "\n",
      "         [[ 2.7100e-02,  1.2158e-01,  1.9336e-01,  ...,  2.1680e-01,\n",
      "            9.4238e-02,  8.4961e-02],\n",
      "          [-2.3242e-01, -1.9727e-01, -3.0664e-01,  ...,  3.3203e-01,\n",
      "            2.5195e-01, -4.5312e-01]],\n",
      "\n",
      "         [[ 8.1543e-02, -7.1777e-02, -2.3682e-02,  ..., -1.2793e-01,\n",
      "            1.8799e-02,  1.3306e-02],\n",
      "          [-3.3951e-04, -2.1484e-02,  2.3828e-01,  ...,  1.5869e-03,\n",
      "            4.5898e-01,  2.8320e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-4.0625, -0.5039, -3.1719,  ..., -4.3750,  2.0625,  0.9609],\n",
      "          [-4.7812, -0.4277, -3.6562,  ..., -4.1875,  1.9922,  0.9531]],\n",
      "\n",
      "         [[-0.6719, -7.2812, -2.4062,  ..., -1.2266,  0.3711, -1.5547],\n",
      "          [-0.6289, -8.0000, -2.7500,  ..., -1.0156,  0.0732, -1.5859]],\n",
      "\n",
      "         [[ 1.3281,  1.0938,  5.2500,  ..., -1.7891, -2.1719, -2.4062],\n",
      "          [ 0.8359,  1.3906,  5.9688,  ..., -1.2344, -1.5859, -3.2188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6875,  4.6562, -1.1953,  ..., -3.7344,  1.6484,  2.0312],\n",
      "          [-1.7422,  4.7188, -1.8047,  ..., -4.3125,  1.8125,  1.4688]],\n",
      "\n",
      "         [[ 1.2969, -1.2422,  2.2031,  ..., -3.2188, -2.1875, -1.8828],\n",
      "          [ 1.4531, -1.2031,  2.5938,  ..., -3.6562, -1.7656, -2.2500]],\n",
      "\n",
      "         [[-1.3359,  1.1406,  2.5469,  ..., -0.0806, -2.3750, -3.4375],\n",
      "          [-1.0859,  1.0547,  2.0938,  ...,  0.1885, -2.5156, -4.2188]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-1.5527e-01, -7.1777e-02,  6.7871e-02,  ..., -5.7861e-02,\n",
      "            5.8105e-02, -7.1777e-02],\n",
      "          [ 2.4609e-01, -8.9844e-02,  3.3203e-01,  ...,  3.8574e-02,\n",
      "           -6.6895e-02,  4.8584e-02]],\n",
      "\n",
      "         [[-1.3867e-01, -1.2500e-01,  2.9053e-02,  ..., -1.7676e-01,\n",
      "           -9.3750e-02, -1.2329e-02],\n",
      "          [-4.2773e-01, -1.2207e-01,  3.6523e-01,  ...,  2.4707e-01,\n",
      "           -3.5742e-01, -2.9688e-01]],\n",
      "\n",
      "         [[ 7.6172e-02,  5.9814e-02,  2.3682e-02,  ..., -1.2695e-01,\n",
      "           -7.9102e-02, -3.7598e-02],\n",
      "          [ 3.9258e-01, -2.4707e-01, -4.0234e-01,  ..., -2.4707e-01,\n",
      "            1.3184e-01, -2.8229e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0681e-04,  2.3193e-03,  6.8848e-02,  ..., -1.9824e-01,\n",
      "            1.9141e-01, -1.0986e-01],\n",
      "          [-1.5039e-01, -1.8945e-01,  1.0889e-01,  ...,  5.3125e-01,\n",
      "           -1.4844e-01, -4.4531e-01]],\n",
      "\n",
      "         [[ 1.4648e-01,  2.6611e-02, -6.7871e-02,  ...,  2.7832e-02,\n",
      "            5.6885e-02,  9.9121e-02],\n",
      "          [ 2.2266e-01, -6.4941e-02, -3.8086e-01,  ...,  1.6797e-01,\n",
      "            9.8145e-02, -4.5703e-01]],\n",
      "\n",
      "         [[-2.3193e-02,  1.6602e-01, -1.2109e-01,  ...,  1.3379e-01,\n",
      "            7.6660e-02, -5.1758e-02],\n",
      "          [ 3.7305e-01, -4.5898e-01, -2.6758e-01,  ..., -3.2959e-02,\n",
      "            2.2266e-01,  1.7871e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.2656,  6.1875, -1.1484,  ..., -0.9609,  2.8281, -1.9766],\n",
      "          [-2.4219,  7.2500, -0.8477,  ..., -1.3750,  2.8438, -1.7031]],\n",
      "\n",
      "         [[ 1.1719,  1.0312,  1.0938,  ...,  0.5586,  1.9219,  2.0312],\n",
      "          [ 1.3594,  1.2656,  0.9883,  ...,  0.2070,  1.9766,  2.2812]],\n",
      "\n",
      "         [[-2.7969, -0.2520,  0.4473,  ..., -0.7109, -2.1406,  1.7031],\n",
      "          [-2.4219, -0.7656,  0.6094,  ..., -0.6289, -2.5312,  1.6406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5312,  1.1328, -2.2031,  ...,  0.7500, -0.7891, -0.7891],\n",
      "          [-4.0312,  2.2344, -3.8750,  ...,  1.2969, -0.9062, -0.9375]],\n",
      "\n",
      "         [[ 0.8359, -0.0767,  3.7812,  ..., -4.0312, -2.8594, -2.6875],\n",
      "          [ 0.8711, -0.1787,  4.3438,  ..., -4.3750, -2.7656, -2.5156]],\n",
      "\n",
      "         [[ 3.1875, -3.5781,  0.8242,  ...,  2.3594,  0.4453,  4.2188],\n",
      "          [ 3.2188, -4.2812,  0.8125,  ...,  2.4688,  0.5820,  4.5312]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0977,  0.2334,  0.1309,  ..., -0.0718,  0.1533, -0.1504],\n",
      "          [-0.1377, -0.0193,  0.0786,  ..., -0.3438,  0.2832,  0.3516]],\n",
      "\n",
      "         [[-0.1494, -0.1113,  0.1177,  ...,  0.2695,  0.0221, -0.0415],\n",
      "          [-0.0564, -0.0171, -0.1377,  ...,  0.1060,  0.1758,  0.4004]],\n",
      "\n",
      "         [[-0.1162, -0.1089, -0.1953,  ..., -0.0718, -0.1035,  0.1855],\n",
      "          [-0.0398, -0.2305, -0.4004,  ...,  0.0488, -0.2676,  0.1670]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0835,  0.1553,  0.2197,  ...,  0.0059, -0.1553,  0.0801],\n",
      "          [-0.1357, -0.2373, -0.4238,  ..., -0.0859, -0.0315, -0.1895]],\n",
      "\n",
      "         [[-0.0210,  0.0253, -0.0033,  ..., -0.4375,  0.0903, -0.0786],\n",
      "          [ 0.2969, -0.4473, -1.0938,  ..., -0.1445,  0.6445, -0.3633]],\n",
      "\n",
      "         [[ 0.1426,  0.0176,  0.0869,  ..., -0.0796,  0.1660, -0.0569],\n",
      "          [ 0.2695, -0.3145,  0.0243,  ..., -0.2891, -0.1050, -0.1631]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[-2.2949e-01,  1.3984e+00, -2.2339e-02,  ..., -4.1992e-01,\n",
      "           -1.4648e-01,  1.1139e-03],\n",
      "          [-5.0391e-01, -1.8066e-01, -3.3203e-01,  ..., -3.1445e-01,\n",
      "           -3.0664e-01, -7.0703e-01]],\n",
      "\n",
      "         [[ 8.0566e-02,  4.1016e-01,  2.1562e+00,  ...,  1.7578e-02,\n",
      "           -6.5918e-02, -2.6953e-01],\n",
      "          [ 1.3379e-01,  3.6328e-01,  1.8984e+00,  ...,  1.0059e-01,\n",
      "           -9.1797e-02, -3.0859e-01]],\n",
      "\n",
      "         [[ 2.9883e-01, -5.3125e-01,  3.2422e-01,  ..., -1.2344e+00,\n",
      "            4.2383e-01, -1.0625e+00],\n",
      "          [ 2.2031e+00, -3.3789e-01,  1.9238e-01,  ..., -2.8594e+00,\n",
      "           -2.0312e-01, -1.2344e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5312e+00, -1.0156e-01, -1.8750e-01,  ..., -7.8613e-02,\n",
      "           -5.8350e-02, -1.4258e-01],\n",
      "          [ 2.7148e-01, -1.7578e-01, -3.7305e-01,  ..., -9.4727e-02,\n",
      "            4.8828e-01,  1.0938e-01]],\n",
      "\n",
      "         [[ 1.2061e-01,  2.4707e-01, -1.3379e-01,  ...,  1.6504e-01,\n",
      "           -2.3340e-01,  1.8652e-01],\n",
      "          [ 6.9885e-03,  7.8125e-01,  1.1865e-01,  ...,  1.2422e+00,\n",
      "            4.8438e-01,  6.8750e-01]],\n",
      "\n",
      "         [[-1.6113e-01, -4.6387e-03, -2.0020e-02,  ...,  4.0283e-03,\n",
      "           -9.2773e-02,  1.9141e-01],\n",
      "          [-6.3672e-01, -2.6855e-02,  2.8711e-01,  ...,  2.6953e-01,\n",
      "           -5.5078e-01, -4.4434e-02]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-1.6309e-01, -8.3984e-02, -2.8711e-01,  ...,  7.9956e-03,\n",
      "            1.8945e-01, -7.4463e-03],\n",
      "          [ 5.9375e-01, -5.0781e-02,  2.4219e-01,  ...,  1.0547e-01,\n",
      "            1.0010e-01,  6.2500e-02]],\n",
      "\n",
      "         [[-2.8442e-02, -5.0537e-02, -2.0752e-03,  ..., -9.1553e-03,\n",
      "            5.5664e-02,  4.4922e-02],\n",
      "          [-1.0078e+00,  3.8672e-01,  4.9414e-01,  ...,  8.3203e-01,\n",
      "            5.3906e-01, -2.2656e-01]],\n",
      "\n",
      "         [[-2.3730e-01, -1.3379e-01, -3.0664e-01,  ...,  9.4238e-02,\n",
      "           -1.4688e+00, -2.2697e-04],\n",
      "          [-6.9531e-01, -3.7500e-01, -1.0254e-01,  ..., -5.6839e-04,\n",
      "           -1.1719e+00,  3.6133e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6223e-03,  4.9316e-02, -1.3062e-02,  ...,  3.5156e-02,\n",
      "            6.9336e-02,  5.7617e-02],\n",
      "          [ 5.3906e-01,  2.4316e-01, -2.9297e-01,  ..., -2.9492e-01,\n",
      "           -3.4766e-01, -6.8359e-02]],\n",
      "\n",
      "         [[-5.0000e-01,  1.7188e-01,  1.9043e-02,  ..., -1.7578e-01,\n",
      "           -1.0303e-01, -2.9297e-01],\n",
      "          [-2.1289e-01,  6.0938e-01, -2.9053e-02,  ...,  4.3164e-01,\n",
      "           -1.0625e+00, -1.9922e-01]],\n",
      "\n",
      "         [[ 2.7466e-02,  5.0354e-03, -4.2188e-01,  ..., -1.4844e-01,\n",
      "           -3.3691e-02,  7.0312e-02],\n",
      "          [-8.6914e-02,  2.0898e-01,  4.4727e-01,  ..., -3.0664e-01,\n",
      "            7.3438e-01, -1.2793e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.4707e-01,  3.8125e+00, -4.9062e+00,  ..., -1.9141e-01,\n",
      "            4.1250e+00,  6.0938e-01],\n",
      "          [-3.3203e-01,  4.6875e+00, -5.4062e+00,  ..., -8.4766e-01,\n",
      "            4.0625e+00,  8.4766e-01]],\n",
      "\n",
      "         [[ 2.5000e+00, -5.5938e+00,  3.1562e+00,  ...,  3.7500e+00,\n",
      "           -8.5156e-01, -1.7500e+00],\n",
      "          [ 2.6250e+00, -4.5625e+00,  3.1875e+00,  ...,  4.0625e+00,\n",
      "           -1.3516e+00, -1.5000e+00]],\n",
      "\n",
      "         [[-1.8047e+00,  6.2256e-02, -9.6875e-01,  ...,  2.4062e+00,\n",
      "            2.7344e+00, -3.0156e+00],\n",
      "          [-1.9766e+00,  2.9492e-01,  6.4453e-01,  ...,  2.8906e+00,\n",
      "            3.1250e+00, -2.5469e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0938e+00,  1.9141e+00, -1.7969e+00,  ..., -7.4062e+00,\n",
      "           -8.9062e-01, -6.2500e-01],\n",
      "          [ 3.6719e+00,  2.1250e+00, -2.0781e+00,  ..., -7.7500e+00,\n",
      "           -1.2031e+00,  5.5078e-01]],\n",
      "\n",
      "         [[-4.2578e-01,  1.2266e+00, -1.2109e+00,  ..., -4.1406e-01,\n",
      "           -6.6562e+00, -3.4375e+00],\n",
      "          [ 4.8828e-01,  1.3047e+00, -1.7656e+00,  ..., -7.7344e-01,\n",
      "           -6.6250e+00, -2.9688e+00]],\n",
      "\n",
      "         [[ 4.1406e-01,  7.7344e-01,  1.6797e+00,  ...,  3.6719e-01,\n",
      "           -6.6406e-01,  1.9844e+00],\n",
      "          [ 1.0889e-01,  8.5547e-01,  1.5078e+00,  ..., -3.6011e-03,\n",
      "           -1.1641e+00,  2.1562e+00]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-1.0437e-02, -3.0518e-02,  5.8350e-02,  ...,  1.2817e-02,\n",
      "           -1.6504e-01, -5.3467e-02],\n",
      "          [ 1.3770e-01,  8.6914e-02,  3.2227e-01,  ..., -4.8584e-02,\n",
      "           -3.0273e-01, -1.1621e-01]],\n",
      "\n",
      "         [[ 5.5420e-02,  5.3955e-02,  7.5195e-02,  ...,  5.8350e-02,\n",
      "           -6.6833e-03,  1.8066e-02],\n",
      "          [ 2.3242e-01,  1.0010e-01,  2.2559e-01,  ...,  1.8652e-01,\n",
      "           -5.3906e-01,  5.0781e-01]],\n",
      "\n",
      "         [[-4.5654e-02, -2.7847e-04, -1.1597e-03,  ...,  6.4453e-02,\n",
      "           -2.0215e-01, -5.2246e-02],\n",
      "          [-3.6523e-01, -4.1016e-01,  4.4727e-01,  ...,  4.3359e-01,\n",
      "            4.4922e-01,  1.0840e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1963e-01,  4.7119e-02, -1.3184e-01,  ...,  4.8828e-02,\n",
      "            1.2695e-01,  2.2949e-02],\n",
      "          [ 1.7090e-01,  3.1250e-01, -1.2512e-03,  ..., -6.3281e-01,\n",
      "            3.7305e-01,  4.4336e-01]],\n",
      "\n",
      "         [[-3.3203e-01, -2.1973e-01, -7.9102e-02,  ..., -4.4336e-01,\n",
      "           -7.7148e-02,  7.4707e-02],\n",
      "          [-1.0547e-01, -2.1387e-01,  1.5039e-01,  ..., -1.9922e-01,\n",
      "           -8.5938e-01,  5.9375e-01]],\n",
      "\n",
      "         [[-1.1182e-01,  2.9663e-02,  6.4941e-02,  ...,  2.1729e-02,\n",
      "           -7.7637e-02,  4.1504e-03],\n",
      "          [ 1.6992e-01,  3.6328e-01,  4.4922e-01,  ..., -6.9141e-01,\n",
      "           -1.2402e-01,  2.5391e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0732,  0.0262, -0.1211,  ..., -0.1992, -0.1216,  0.2852],\n",
      "          [ 0.4707, -0.0549, -0.4902,  ..., -0.5547,  0.1094,  0.3359]],\n",
      "\n",
      "         [[ 0.1689, -0.1885, -0.1118,  ..., -0.0294,  0.0271, -0.0615],\n",
      "          [-0.2676, -0.7812, -0.3516,  ..., -0.3262,  0.0098,  0.0933]],\n",
      "\n",
      "         [[ 0.1436, -0.0239,  0.4531,  ..., -0.0245, -0.2041, -0.0742],\n",
      "          [-0.5312, -0.2598,  0.3418,  ..., -0.0618, -0.3379, -0.5781]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3066,  0.1436,  0.1069,  ..., -0.1680, -0.0713, -0.0515],\n",
      "          [-0.2949,  0.2930,  1.0156,  ..., -0.4473, -1.1562,  0.6055]],\n",
      "\n",
      "         [[-0.2637, -0.4219,  0.3906,  ..., -0.7969,  0.2236,  0.2188],\n",
      "          [-0.1523, -0.2871,  0.8125,  ..., -1.2109,  0.3652,  0.5625]],\n",
      "\n",
      "         [[ 0.5703,  0.1875, -0.2871,  ..., -0.3164,  0.1318, -0.0894],\n",
      "          [ 0.5781,  0.4512, -0.6445,  ..., -0.1289, -0.2139,  0.3535]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0559, -0.0310, -0.0635,  ..., -0.0508,  0.0243, -0.0247],\n",
      "          [ 0.2910,  0.1357, -0.4121,  ..., -0.4863, -0.1855, -0.4297]],\n",
      "\n",
      "         [[-0.0117, -0.0053, -0.0173,  ..., -0.0315,  0.0041,  0.0250],\n",
      "          [-0.3105,  0.2695,  0.0226,  ..., -0.2188, -0.0688, -0.5000]],\n",
      "\n",
      "         [[-0.0277,  0.0266, -0.0271,  ...,  0.0312,  0.0503, -0.0019],\n",
      "          [ 0.3672,  0.1406, -0.4590,  ...,  0.8242, -0.4102, -0.4297]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1108,  0.0437,  0.0977,  ..., -0.0562,  0.0262, -0.0532],\n",
      "          [ 0.3828, -0.6914,  0.3770,  ..., -0.1514, -0.0037,  0.0466]],\n",
      "\n",
      "         [[ 0.0320, -0.0688,  0.0118,  ..., -0.0128,  0.0183, -0.0201],\n",
      "          [-0.1035,  0.1260,  0.1885,  ...,  0.2852, -0.5195, -0.2021]],\n",
      "\n",
      "         [[-0.0052, -0.0181,  0.0405,  ..., -0.0090, -0.0015, -0.0027],\n",
      "          [ 0.4082, -0.1040, -0.0439,  ...,  0.4141,  1.4844, -0.2988]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3906,  0.2969,  2.4062,  ...,  1.5547,  2.1875,  3.2344],\n",
      "          [-2.6719,  0.2578,  2.8750,  ...,  1.3359,  1.7812,  3.0938]],\n",
      "\n",
      "         [[-2.3125,  0.5312,  1.4844,  ...,  3.2656, -0.6641, -0.9414],\n",
      "          [-2.2500,  0.7539,  0.6172,  ...,  2.8125, -0.8359, -0.8477]],\n",
      "\n",
      "         [[-4.3438,  1.2578,  3.4219,  ...,  2.3750, -3.1094, -4.4688],\n",
      "          [-4.5938,  1.7188,  3.7344,  ...,  2.7656, -4.4375, -5.0625]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9609,  1.5078,  4.2188,  ..., -2.5156,  3.9062, -0.4121],\n",
      "          [-0.3477,  1.1094,  4.2188,  ..., -3.5000,  4.1250, -0.6484]],\n",
      "\n",
      "         [[-5.8750, -1.8906, -0.0601,  ...,  4.0000, -1.0859, -3.3438],\n",
      "          [-5.1250, -2.1719, -0.3027,  ...,  4.4062, -0.9961, -3.8594]],\n",
      "\n",
      "         [[ 2.1094, -1.1250, -1.8047,  ...,  0.9844, -2.0938,  3.8281],\n",
      "          [ 1.9375, -1.4609, -1.8906,  ...,  0.7812, -2.5625,  3.6094]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0654, -0.0410,  0.0625,  ...,  0.0442, -0.0554,  0.0635],\n",
      "          [-0.0079, -0.1836,  0.2363,  ..., -0.7148,  0.2051,  0.1211]],\n",
      "\n",
      "         [[-0.0361,  0.0996, -0.0674,  ...,  0.0603,  0.0481,  0.0300],\n",
      "          [-0.3887,  0.2812,  0.5430,  ...,  0.1235, -0.3711,  0.0918]],\n",
      "\n",
      "         [[-0.0129, -0.0747, -0.0449,  ..., -0.1050,  0.0109, -0.0081],\n",
      "          [ 1.0234, -1.0156,  0.6328,  ...,  0.1436, -0.9844,  0.1660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0243,  0.1030,  0.0304,  ..., -0.0645,  0.0684, -0.0239],\n",
      "          [ 0.0708, -0.1934, -0.3457,  ...,  0.0620,  0.0287, -0.3105]],\n",
      "\n",
      "         [[-0.0459, -0.1030, -0.1416,  ..., -0.0605, -0.0276,  0.0854],\n",
      "          [ 0.0928, -0.4023, -0.2988,  ...,  0.1084, -0.2314, -0.3340]],\n",
      "\n",
      "         [[ 0.0101, -0.0415,  0.0654,  ...,  0.0615,  0.0461,  0.0391],\n",
      "          [ 0.0674,  0.3379, -0.4121,  ..., -0.0947,  0.2217,  0.0820]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0277, -0.2539, -1.0547,  ..., -0.6719, -0.2969, -0.2207],\n",
      "          [-0.4121,  0.0283, -1.1875,  ..., -0.9727, -0.3320, -0.0757]],\n",
      "\n",
      "         [[-0.0425, -0.3223,  0.0139,  ..., -0.2217, -0.1289, -0.1885],\n",
      "          [-0.3730, -0.4414, -0.0256,  ..., -0.3906, -0.1064,  0.2256]],\n",
      "\n",
      "         [[ 0.2598, -0.4980, -0.2812,  ..., -0.0762,  0.3711,  0.7578],\n",
      "          [-0.4141, -0.2793, -0.6680,  ..., -0.3438,  0.5430,  0.5547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2715, -0.0635, -0.0781,  ..., -0.1992,  0.0084, -0.0649],\n",
      "          [ 0.1562,  0.1689, -0.5742,  ...,  0.0364, -0.0378,  0.2041]],\n",
      "\n",
      "         [[ 0.0708, -0.4492,  0.2578,  ..., -0.0728,  0.1260,  0.1016],\n",
      "          [-0.0219, -0.7227,  0.4297,  ..., -0.2852,  0.2559, -0.3398]],\n",
      "\n",
      "         [[ 0.1328,  0.4844,  0.2559,  ...,  0.3516,  0.1377, -0.1475],\n",
      "          [-0.2090,  0.6133,  0.3066,  ...,  0.3828,  0.1621, -0.1611]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0417,  0.0747,  0.0334,  ..., -0.0977, -0.0603,  0.0850],\n",
      "          [-0.4082,  0.2754, -0.3320,  ..., -0.3477,  0.2559,  0.1855]],\n",
      "\n",
      "         [[-0.0928,  0.0659,  0.0908,  ..., -0.0471,  0.0869, -0.0413],\n",
      "          [ 0.0048,  0.1533,  0.1021,  ...,  0.2373,  1.0547,  0.3926]],\n",
      "\n",
      "         [[ 0.0302,  0.0197, -0.0267,  ..., -0.0442,  0.0182,  0.0325],\n",
      "          [-0.0083,  0.6016,  0.0189,  ..., -0.3301, -0.1934,  0.9180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0376, -0.0051, -0.0309,  ...,  0.0107,  0.0269,  0.0840],\n",
      "          [-0.0342, -0.0427,  0.3359,  ...,  0.2471, -0.6055, -0.3672]],\n",
      "\n",
      "         [[-0.1396, -0.0510,  0.1338,  ...,  0.0884,  0.1235,  0.0537],\n",
      "          [ 0.2031,  0.5586,  0.1758,  ..., -0.5859,  0.0581,  0.8438]],\n",
      "\n",
      "         [[-0.0835,  0.0233, -0.2061,  ..., -0.0376, -0.0197,  0.0461],\n",
      "          [ 0.4082,  0.8906, -0.1504,  ..., -0.0330, -0.0275,  0.7578]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[-3.5625,  3.9062, -2.1250,  ..., -0.6016,  3.0938, -4.0625],\n",
      "          [-4.8750,  3.9688, -2.7500,  ..., -0.2949,  3.4688, -4.0000]],\n",
      "\n",
      "         [[-4.9688,  0.3984,  2.0469,  ...,  2.8125,  5.1250, -4.4688],\n",
      "          [-5.2188,  0.5977,  1.6094,  ...,  2.8438,  5.7500, -5.0938]],\n",
      "\n",
      "         [[ 1.6562,  0.4629, -1.6719,  ...,  0.2188, -0.4141,  0.8945],\n",
      "          [ 1.7969,  1.2578, -1.3281,  ..., -0.1172, -0.5000,  1.3047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4961,  1.2656, -1.0391,  ..., -0.6953,  0.1079,  1.0312],\n",
      "          [ 0.9492,  1.2891, -0.6406,  ..., -0.5234, -0.0708,  1.2969]],\n",
      "\n",
      "         [[-6.0312,  1.8359, -4.5312,  ..., -2.4062,  2.4219,  3.2812],\n",
      "          [-5.5312,  2.1094, -4.9375,  ..., -2.7500,  2.7188,  3.3750]],\n",
      "\n",
      "         [[-2.3906, -1.6250, -5.3438,  ..., -2.7500,  1.4062,  1.4688],\n",
      "          [-2.7656, -1.7109, -5.4688,  ..., -2.9062,  1.8672,  1.5859]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0684, -0.0830,  0.0898,  ...,  0.1504, -0.0557, -0.0085],\n",
      "          [-0.2236, -0.4414, -0.1914,  ...,  0.1611,  0.7539,  0.0635]],\n",
      "\n",
      "         [[ 0.0217, -0.0122,  0.0067,  ..., -0.1226,  0.1416,  0.0251],\n",
      "          [ 0.0078, -0.1113,  0.4492,  ...,  0.3652,  0.2910, -0.2441]],\n",
      "\n",
      "         [[-0.0193, -0.0923,  0.0481,  ...,  0.0962,  0.0342, -0.0164],\n",
      "          [ 0.0073,  0.2031,  0.5039,  ...,  0.7344,  0.9062, -0.9219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0159, -0.0109,  0.1973,  ..., -0.0977,  0.0089, -0.0659],\n",
      "          [-0.7266,  0.7422,  0.1895,  ...,  0.2422, -0.0947,  0.4707]],\n",
      "\n",
      "         [[-0.0231, -0.0884, -0.0630,  ...,  0.0913, -0.0571, -0.0654],\n",
      "          [ 0.0674, -0.1699, -0.0569,  ...,  0.4688, -0.2217,  0.0923]],\n",
      "\n",
      "         [[-0.0698,  0.1040,  0.0549,  ..., -0.0181, -0.0972, -0.0486],\n",
      "          [-0.0544,  0.0693,  0.2080,  ...,  0.0776,  0.2393, -0.0967]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.1641,  0.1074,  0.2656,  ..., -0.2773, -0.0776, -0.3613],\n",
      "          [ 0.7969, -0.2090,  0.4277,  ..., -0.5625, -0.8750, -0.5469]],\n",
      "\n",
      "         [[ 0.2168, -0.0903, -0.1631,  ...,  0.0801, -0.1650, -0.0537],\n",
      "          [-0.3086, -0.1543, -0.1367,  ...,  0.3750, -0.1738,  0.4707]],\n",
      "\n",
      "         [[ 0.4453, -0.3477,  0.3594,  ...,  0.0913, -0.4180,  0.0864],\n",
      "          [-0.0251,  0.0266,  0.5312,  ...,  0.2754, -0.9023,  0.0962]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0217,  0.0432,  0.5117,  ...,  0.2949, -0.4141, -0.0398],\n",
      "          [-0.2080,  0.3145, -0.3633,  ...,  0.3672, -0.1963,  0.9688]],\n",
      "\n",
      "         [[-0.4668,  0.2676, -0.0228,  ...,  0.0276,  0.1475, -0.3750],\n",
      "          [-0.3789,  0.0023, -0.7266,  ...,  0.1973,  0.6484, -0.1138]],\n",
      "\n",
      "         [[ 0.1030,  0.0354, -0.4609,  ..., -0.0928,  0.1250, -0.1025],\n",
      "          [-0.0825, -0.3711,  0.5430,  ...,  0.0742, -0.0889,  0.2090]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 3.8574e-02, -4.0039e-02, -1.2695e-01,  ..., -1.7334e-02,\n",
      "           -4.0527e-02, -3.1982e-02],\n",
      "          [ 5.8594e-02,  6.8750e-01,  1.3867e-01,  ..., -1.6406e-01,\n",
      "            4.0820e-01,  5.0781e-01]],\n",
      "\n",
      "         [[ 2.8564e-02, -2.1851e-02,  6.5918e-02,  ..., -1.4221e-02,\n",
      "           -3.2227e-02, -7.0312e-02],\n",
      "          [ 1.9824e-01, -2.1973e-01, -9.5215e-02,  ..., -9.9609e-02,\n",
      "            3.9648e-01, -1.2109e-01]],\n",
      "\n",
      "         [[-1.3477e-01,  8.9645e-04, -1.3965e-01,  ...,  1.4160e-01,\n",
      "            5.9570e-02,  3.9795e-02],\n",
      "          [-2.1289e-01, -8.7109e-01, -2.3438e-01,  ...,  1.6699e-01,\n",
      "           -1.6309e-01,  2.8320e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3965e-02, -2.0996e-02, -7.9590e-02,  ..., -1.0559e-02,\n",
      "            8.0566e-03,  8.0566e-03],\n",
      "          [ 9.4141e-01,  6.4453e-01, -6.3672e-01,  ...,  4.8523e-03,\n",
      "            7.4219e-02, -1.3965e-01]],\n",
      "\n",
      "         [[ 2.9541e-02, -1.6602e-02,  3.8086e-02,  ...,  4.2114e-03,\n",
      "            3.2654e-03, -9.5825e-03],\n",
      "          [ 3.9062e-01,  7.2656e-01, -1.8848e-01,  ...,  8.7109e-01,\n",
      "            7.5781e-01,  1.2988e-01]],\n",
      "\n",
      "         [[ 7.3730e-02, -8.9355e-02, -5.3223e-02,  ...,  7.6172e-02,\n",
      "            4.8828e-02,  3.3447e-02],\n",
      "          [ 1.8457e-01, -5.7861e-02, -2.0215e-01,  ..., -1.2360e-03,\n",
      "           -4.8633e-01, -2.3315e-02]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.6172,  1.0547, -2.2031,  ..., -1.9453,  0.0938,  1.8906],\n",
      "          [-1.7969,  1.3203, -1.9141,  ..., -2.4219,  0.3262,  2.4062]],\n",
      "\n",
      "         [[ 0.7305,  0.1768,  1.3672,  ..., -4.2188,  0.6758,  3.2188],\n",
      "          [ 1.2969,  0.4727,  1.4609,  ..., -5.3125,  0.8281,  3.6719]],\n",
      "\n",
      "         [[-2.5781, -1.2344,  0.8984,  ...,  1.1328,  1.7422, -2.7812],\n",
      "          [-2.7500, -1.2266,  1.0391,  ...,  1.6719,  0.8320, -2.9062]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7031, -4.1875, -2.3125,  ..., -2.0312,  0.8477, -1.2188],\n",
      "          [-3.3281, -4.4375, -1.7109,  ..., -1.8438,  0.7734, -0.8555]],\n",
      "\n",
      "         [[ 1.6328, -0.8086, -0.0527,  ..., -0.7734, -0.2793, -0.1592],\n",
      "          [ 1.3594, -0.5117, -0.0776,  ..., -0.6055, -0.5078, -0.2129]],\n",
      "\n",
      "         [[-0.1328,  1.2734, -0.1328,  ...,  2.4688, -1.3672, -0.3672],\n",
      "          [-1.1719,  1.7188,  0.2041,  ...,  3.3594, -1.5703,  0.1748]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 6.2988e-02, -2.7588e-02, -7.1716e-03,  ..., -1.5747e-02,\n",
      "           -3.4790e-03,  4.3213e-02],\n",
      "          [ 8.6914e-02,  1.1035e-01, -3.3594e-01,  ..., -3.9453e-01,\n",
      "            6.8359e-01, -1.9684e-03]],\n",
      "\n",
      "         [[ 2.9541e-02,  1.5747e-02, -9.7046e-03,  ..., -6.8054e-03,\n",
      "            1.0889e-01, -2.0703e-01],\n",
      "          [ 1.2188e+00, -1.3379e-01,  2.7539e-01,  ...,  4.5703e-01,\n",
      "           -6.9141e-01, -2.5977e-01]],\n",
      "\n",
      "         [[ 2.9102e-01,  4.9438e-03, -9.2285e-02,  ..., -5.8594e-02,\n",
      "           -1.0498e-01, -6.5308e-03],\n",
      "          [-1.9043e-01,  3.5742e-01, -4.6289e-01,  ...,  3.4766e-01,\n",
      "            1.0078e+00,  3.2617e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7588e-02,  1.5625e-02, -6.6895e-02,  ..., -1.2988e-01,\n",
      "            5.7373e-02, -8.3008e-02],\n",
      "          [ 4.0820e-01,  8.3203e-01, -3.7109e-01,  ..., -1.1133e-01,\n",
      "           -4.7266e-01, -3.6914e-01]],\n",
      "\n",
      "         [[ 3.9453e-01, -1.2695e-01,  6.0303e-02,  ...,  1.7738e-04,\n",
      "            1.9043e-02, -5.4199e-02],\n",
      "          [ 7.7637e-02, -4.6484e-01, -5.5176e-02,  ..., -2.9883e-01,\n",
      "           -2.1191e-01, -4.0039e-01]],\n",
      "\n",
      "         [[ 3.4180e-02, -1.2500e-01,  1.3867e-01,  ...,  8.9355e-02,\n",
      "           -1.0352e-01,  2.0386e-02],\n",
      "          [ 5.6250e-01, -1.0312e+00,  5.5908e-02,  ...,  1.0254e-01,\n",
      "            6.2109e-01,  4.2383e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.5352,  0.5547, -1.3828,  ...,  0.3691,  0.2100, -0.0737],\n",
      "          [ 0.6523,  0.8086,  0.5703,  ...,  0.8867, -0.2266, -0.2812]],\n",
      "\n",
      "         [[ 0.4297, -0.0109,  0.0153,  ..., -0.0947, -0.0698,  0.3496],\n",
      "          [ 0.5469, -0.9180,  0.2539,  ...,  0.2734, -0.4883, -1.7500]],\n",
      "\n",
      "         [[ 0.2422,  0.0299, -0.2354,  ...,  0.1934,  0.3223, -0.1982],\n",
      "          [-0.2168,  0.0884,  0.9141,  ..., -0.0019,  0.0203, -0.5469]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2471,  0.0825, -0.2432,  ...,  0.2061, -0.0493,  0.1895],\n",
      "          [ 0.3145, -0.1245,  0.1729,  ...,  0.0422, -0.2080, -0.1377]],\n",
      "\n",
      "         [[ 0.4004, -0.0115, -0.0396,  ..., -0.0967, -0.0203,  0.0952],\n",
      "          [ 0.3789, -0.1982, -0.2188,  ...,  0.5547,  0.6367,  0.1250]],\n",
      "\n",
      "         [[-0.1406,  0.0977,  0.3750,  ..., -0.1040,  0.0796,  0.4883],\n",
      "          [ 0.2480,  0.6719,  0.5117,  ...,  0.0640,  0.0515,  0.1768]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-1.1035e-01, -3.8574e-02,  6.3171e-03,  ..., -7.9346e-03,\n",
      "            7.2021e-03, -8.0490e-04],\n",
      "          [ 3.9551e-02, -4.6875e-02,  5.9375e-01,  ..., -1.7944e-02,\n",
      "            3.3789e-01,  9.7656e-01]],\n",
      "\n",
      "         [[-3.1494e-02,  4.5166e-02,  3.1586e-03,  ..., -8.1543e-02,\n",
      "           -3.1006e-02, -2.5757e-02],\n",
      "          [-1.1572e-01, -4.3945e-01,  1.9629e-01,  ...,  6.5234e-01,\n",
      "           -1.0352e-01, -4.8242e-01]],\n",
      "\n",
      "         [[ 1.8555e-02, -1.3428e-03, -6.4453e-02,  ...,  1.9287e-02,\n",
      "           -4.9805e-02, -1.6602e-02],\n",
      "          [ 2.8711e-01,  1.4355e-01, -2.9102e-01,  ..., -4.5703e-01,\n",
      "            3.2471e-02,  3.8672e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1106e-03,  4.6875e-02, -1.0059e-01,  ..., -3.7842e-02,\n",
      "           -1.6602e-02, -5.6458e-03],\n",
      "          [ 3.0518e-04, -4.2969e-01,  5.3516e-01,  ...,  4.2578e-01,\n",
      "            4.2188e-01, -2.4805e-01]],\n",
      "\n",
      "         [[ 7.7148e-02, -2.0264e-02, -4.8096e-02,  ..., -1.8433e-02,\n",
      "            3.2715e-02,  6.9580e-03],\n",
      "          [-3.6133e-01, -5.6152e-03,  2.7734e-01,  ..., -4.3750e-01,\n",
      "            3.6719e-01, -5.4199e-02]],\n",
      "\n",
      "         [[-4.6631e-02, -4.5410e-02, -1.9409e-02,  ...,  1.1108e-02,\n",
      "           -1.1215e-03, -1.9775e-02],\n",
      "          [-2.6611e-02,  2.2949e-01,  4.5508e-01,  ..., -6.2500e-01,\n",
      "            5.7617e-02,  2.0605e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0078, -0.3789, -1.6250,  ...,  0.8242,  0.5977,  2.0312],\n",
      "          [ 1.7422, -0.4238, -2.0156,  ...,  0.9961,  0.2949,  2.2500]],\n",
      "\n",
      "         [[ 1.4688,  0.6016, -1.7578,  ..., -1.4609,  0.4902,  1.1797],\n",
      "          [ 1.5156,  0.6211, -2.1406,  ..., -1.7188,  0.5664,  0.9453]],\n",
      "\n",
      "         [[ 0.2871, -0.6523,  1.2031,  ..., -0.3867,  0.3125, -2.0156],\n",
      "          [ 0.4258,  0.1226,  1.5391,  ..., -0.4961,  0.1074, -2.4688]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1406,  1.2578,  1.2891,  ...,  0.4883,  1.9609, -0.0325],\n",
      "          [ 1.2891,  1.2734,  1.4453,  ...,  0.5430,  2.5625, -0.1426]],\n",
      "\n",
      "         [[ 1.9375,  0.9727, -1.7891,  ..., -1.8438,  3.1250,  1.9922],\n",
      "          [ 2.0000,  0.7344, -1.4844,  ..., -1.5234,  3.3438,  1.7188]],\n",
      "\n",
      "         [[-1.5859, -0.5586, -0.9180,  ..., -1.4141, -0.0996, -1.1016],\n",
      "          [-1.4844, -0.3750, -2.6875,  ..., -1.2891, -0.0342, -1.1016]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0103, -0.0281,  0.0186,  ...,  0.1260,  0.0288, -0.0298],\n",
      "          [-0.4004, -0.5156,  0.2871,  ..., -0.2891,  0.2188, -0.6602]],\n",
      "\n",
      "         [[-0.0630, -0.0425,  0.0327,  ..., -0.0349,  0.0135,  0.0233],\n",
      "          [-0.0718, -0.7500,  0.3887,  ..., -0.0796, -0.4375,  0.7891]],\n",
      "\n",
      "         [[ 0.0483,  0.0437, -0.0825,  ...,  0.0374, -0.0400,  0.0933],\n",
      "          [ 0.1074, -0.0092, -0.3184,  ...,  0.3301, -0.0547, -0.4043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0238, -0.0474, -0.0061,  ...,  0.2793, -0.1348, -0.0801],\n",
      "          [ 0.1396, -0.1172,  0.0952,  ...,  0.2197,  0.0703, -0.6523]],\n",
      "\n",
      "         [[-0.2754, -0.3008,  0.0737,  ..., -0.1104, -0.0610, -0.0654],\n",
      "          [ 0.1377,  0.5977,  0.0427,  ...,  0.1177, -0.4004, -0.7773]],\n",
      "\n",
      "         [[ 0.0131,  0.0021,  0.0405,  ...,  0.0047,  0.0149, -0.0128],\n",
      "          [-0.1001, -0.0124,  0.2041,  ...,  0.3906, -0.2031, -0.1777]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0106,  0.0354,  0.2715,  ...,  1.1406,  0.2412, -0.0422],\n",
      "          [ 0.0249, -0.5625, -0.8125,  ..., -0.2930,  0.3320,  0.0742]],\n",
      "\n",
      "         [[-0.2188, -0.2227, -0.3555,  ..., -0.0439,  0.0344, -0.4824],\n",
      "          [ 1.6641,  0.5430, -0.3555,  ..., -0.3223,  0.4941,  0.2217]],\n",
      "\n",
      "         [[ 0.3145,  0.0620, -0.0496,  ...,  0.0371,  0.1416,  0.2217],\n",
      "          [ 0.7070, -0.4023, -0.4805,  ...,  0.1855, -0.2656, -0.3203]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3320, -0.3438, -0.0126,  ...,  0.0933,  0.0432,  0.2637],\n",
      "          [-0.0417, -0.4141, -0.0359,  ...,  0.0508, -0.5664, -0.0195]],\n",
      "\n",
      "         [[ 0.2100,  0.0574, -1.0625,  ..., -0.1147,  0.3105, -0.1982],\n",
      "          [ 0.3164,  0.0166,  1.0469,  ...,  0.2539,  0.4961, -0.7734]],\n",
      "\n",
      "         [[-0.2490, -0.5586,  0.1572,  ...,  0.3359,  0.2109,  0.1396],\n",
      "          [-0.4043, -0.8633, -0.1572,  ...,  0.9023,  0.3301, -0.0889]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0024,  0.0454, -0.0308,  ...,  0.0330,  0.0093,  0.0186],\n",
      "          [-0.4785, -0.0938,  0.9492,  ..., -0.9531,  0.3691,  0.5508]],\n",
      "\n",
      "         [[-0.1045,  0.0422,  0.0090,  ..., -0.0354,  0.0304,  0.0332],\n",
      "          [ 0.3066, -0.2969,  0.0371,  ...,  0.8789, -0.1299,  0.6680]],\n",
      "\n",
      "         [[-0.0630,  0.3535,  0.3945,  ...,  0.6680,  0.7188, -0.0150],\n",
      "          [-0.0957, -0.7109, -0.7148,  ..., -0.6289, -0.9844,  0.0106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0086,  0.0427, -0.0287,  ...,  0.0576,  0.0269, -0.0654],\n",
      "          [-0.1118,  0.0210, -0.4023,  ..., -0.7031, -0.1523, -0.2637]],\n",
      "\n",
      "         [[-0.0884, -0.1465,  0.0942,  ..., -0.0017,  0.0029,  0.0131],\n",
      "          [ 0.2559,  0.6562,  0.3574,  ..., -0.4668,  0.0149,  0.6211]],\n",
      "\n",
      "         [[-0.1104,  0.0131, -0.1289,  ...,  0.0640, -0.0120,  0.0991],\n",
      "          [ 0.0544,  0.1387,  0.1396,  ...,  0.5625,  0.0913, -0.4590]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.8125,  0.3359,  0.0933,  ..., -0.9648,  1.1172,  0.0850],\n",
      "          [ 0.9727, -0.2480, -0.7383,  ..., -1.1250,  0.5469, -0.0747]],\n",
      "\n",
      "         [[ 0.7461, -0.6367, -1.1875,  ..., -0.2773, -1.3281, -0.0021],\n",
      "          [ 0.4590, -0.5117, -1.2734,  ..., -0.3965, -0.7461, -0.3906]],\n",
      "\n",
      "         [[-0.7695, -0.3203, -0.5000,  ...,  1.0000, -0.7617, -0.7539],\n",
      "          [-1.1016, -0.7656, -0.6992,  ...,  1.1172, -1.2656, -1.3281]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1406,  0.7227,  0.4121,  ...,  0.1279, -0.3027,  0.6094],\n",
      "          [ 0.3125,  0.6289,  0.5352,  ..., -0.2676, -0.1963,  0.1787]],\n",
      "\n",
      "         [[-1.5469, -0.2656, -1.2109,  ..., -0.2500,  0.6992, -0.8242],\n",
      "          [-1.7344, -0.6289, -1.7266,  ...,  0.0239,  0.7148, -0.7812]],\n",
      "\n",
      "         [[ 0.3496, -0.5156,  1.2422,  ..., -0.4453,  0.2422, -0.0225],\n",
      "          [ 0.2432, -0.6484,  1.6641,  ..., -0.4082,  0.3867, -0.2676]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0981, -0.1631, -0.0454,  ...,  0.1182,  0.3184,  0.0405],\n",
      "          [ 0.0250, -0.2852, -0.6055,  ..., -0.5898,  0.3281, -1.0703]],\n",
      "\n",
      "         [[-0.3086,  0.2158,  0.1445,  ..., -0.1650, -0.3613,  0.3672],\n",
      "          [ 0.4199,  0.2393,  0.3125,  ...,  0.6484,  0.6875, -0.2734]],\n",
      "\n",
      "         [[-0.1260, -0.0996, -0.2383,  ...,  0.0374,  0.1201, -0.0513],\n",
      "          [-0.5977,  0.4883,  0.3828,  ...,  0.1177,  0.2383, -0.4746]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0393, -0.0801, -0.2197,  ...,  0.4395,  0.1660, -0.0173],\n",
      "          [ 0.1572,  0.4043, -0.0503,  ..., -0.0236, -0.2373, -0.8047]],\n",
      "\n",
      "         [[ 0.0591,  0.1021,  0.0216,  ...,  0.1416, -0.0403, -0.0065],\n",
      "          [ 0.3027, -0.4590, -0.2891,  ...,  0.2217,  0.2949, -0.1514]],\n",
      "\n",
      "         [[ 0.0425, -0.0305, -0.3496,  ..., -0.0442,  0.0154,  0.2158],\n",
      "          [ 0.0913,  0.2852, -0.2559,  ...,  0.1641,  0.1846, -0.0820]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0796, -0.3438, -0.0679,  ..., -0.2852,  0.2344, -0.1572],\n",
      "          [-0.2891, -0.6758,  0.1709,  ...,  0.1494,  0.2871, -0.0239]],\n",
      "\n",
      "         [[-0.3242,  1.3047,  0.2559,  ...,  0.2559,  0.1426,  0.1143],\n",
      "          [-0.2949, -0.4062,  0.0752,  ..., -0.2158,  0.3164,  0.2656]],\n",
      "\n",
      "         [[ 0.1592, -0.1201,  0.0420,  ...,  0.1494,  0.1104,  0.1436],\n",
      "          [ 0.8047, -0.3223,  0.2676,  ...,  0.4492, -0.0535,  0.5586]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2539, -0.6914,  0.0947,  ...,  0.0630, -0.0520, -0.0786],\n",
      "          [-0.2002, -0.7773,  0.4023,  ..., -0.1147,  0.7812, -0.3125]],\n",
      "\n",
      "         [[-0.2871, -0.0830, -0.0435,  ..., -0.0036,  0.2773,  0.0400],\n",
      "          [-0.6797, -0.3320,  0.0771,  ..., -0.1709,  0.6914, -0.4844]],\n",
      "\n",
      "         [[-0.0177,  0.2334,  0.1191,  ..., -0.1084, -0.3887, -0.1826],\n",
      "          [-0.3320,  0.1016,  0.2383,  ..., -0.4023, -0.4258, -1.0469]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-2.2583e-02,  2.6611e-02,  4.7852e-02,  ..., -2.1484e-02,\n",
      "            2.7954e-02,  9.0820e-02],\n",
      "          [ 3.5742e-01,  4.1504e-02,  1.1572e-01,  ..., -7.9590e-02,\n",
      "           -4.0234e-01, -8.4961e-02]],\n",
      "\n",
      "         [[-1.6895e-01,  1.8433e-02, -1.0400e-01,  ..., -5.9570e-02,\n",
      "            7.1289e-02, -2.1973e-01],\n",
      "          [-4.4922e-01, -1.3965e-01,  7.8906e-01,  ..., -4.0430e-01,\n",
      "            5.5469e-01, -3.1445e-01]],\n",
      "\n",
      "         [[ 1.2695e-02,  9.4238e-02,  5.3101e-03,  ...,  6.3171e-03,\n",
      "           -7.0312e-02, -8.7891e-02],\n",
      "          [-5.1514e-02, -1.9897e-02,  4.7070e-01,  ...,  1.0352e-01,\n",
      "            1.1084e-01,  2.5781e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8594e-03, -2.9907e-02,  3.2471e-02,  ..., -1.0193e-02,\n",
      "            4.1260e-02, -4.7874e-04],\n",
      "          [-2.0508e-01,  3.6914e-01, -5.6152e-02,  ...,  5.1953e-01,\n",
      "           -3.4180e-01,  5.1562e-01]],\n",
      "\n",
      "         [[-4.5166e-02,  7.7148e-02,  7.2021e-03,  ...,  1.4587e-02,\n",
      "            4.9316e-02,  1.6113e-02],\n",
      "          [-6.2109e-01, -4.7266e-01,  2.3730e-01,  ...,  1.1816e-01,\n",
      "           -6.2891e-01,  6.1328e-01]],\n",
      "\n",
      "         [[-5.0659e-03,  5.4688e-02, -1.9379e-03,  ..., -5.9570e-02,\n",
      "            7.8613e-02, -2.9541e-02],\n",
      "          [ 2.0215e-01,  1.4844e-01,  2.0605e-01,  ...,  9.0332e-02,\n",
      "           -2.3535e-01,  2.9297e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.1807, -0.4531,  0.3242,  ...,  0.0811, -0.8008,  0.0264],\n",
      "          [ 0.3457,  0.0596,  0.5430,  ..., -0.3750, -0.5938, -0.2617]],\n",
      "\n",
      "         [[ 0.3223,  0.2275, -0.4688,  ..., -0.2061, -0.4121, -0.3047],\n",
      "          [ 0.0532,  0.0908, -0.9141,  ..., -0.9961, -0.4805, -0.4434]],\n",
      "\n",
      "         [[ 0.7266,  1.2109, -0.2461,  ...,  0.7773,  0.4531,  0.4160],\n",
      "          [ 0.6016,  1.3516, -0.2109,  ...,  0.9648,  0.7461,  0.2891]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2090, -1.2188,  0.5898,  ..., -0.1650, -0.4258, -0.5898],\n",
      "          [ 0.1660, -1.1875, -0.4297,  ...,  0.0623, -1.8516, -0.8516]],\n",
      "\n",
      "         [[-1.0547,  0.3223,  0.2734,  ..., -0.4238, -0.1758, -0.3359],\n",
      "          [-1.5547,  0.5508,  0.8828,  ..., -0.4297, -0.1514, -0.1758]],\n",
      "\n",
      "         [[-0.5508,  0.1299, -0.0277,  ..., -0.0718,  1.1875, -0.3340],\n",
      "          [-0.1436, -0.1094,  0.2773,  ...,  0.4238,  1.3906, -0.2012]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0791,  0.0820, -0.0503,  ..., -0.0449, -0.0518, -0.0070],\n",
      "          [ 0.4219,  0.3125,  0.0408,  ...,  0.0197, -0.1289, -0.1816]],\n",
      "\n",
      "         [[-0.2227,  0.1128,  0.2246,  ..., -0.1680, -0.1143, -0.2656],\n",
      "          [-0.8438,  0.5547,  0.1060,  ...,  0.2129,  0.0081, -0.8867]],\n",
      "\n",
      "         [[-0.1855, -0.0334, -0.1377,  ..., -0.0054,  0.0569,  0.0566],\n",
      "          [ 0.1455, -0.6250,  0.2812,  ..., -0.0255,  0.2334,  0.0043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3457,  0.1206, -0.0422,  ..., -0.0432,  0.2578, -0.1299],\n",
      "          [-0.3164,  0.5391,  0.1514,  ..., -0.0415, -0.0361, -0.4883]],\n",
      "\n",
      "         [[ 0.1826, -0.0464,  0.1465,  ..., -0.0540, -0.0530,  0.1475],\n",
      "          [ 0.1758, -0.3262, -0.3887,  ...,  0.0674,  1.0234, -0.0723]],\n",
      "\n",
      "         [[-0.1128, -0.0265, -0.0022,  ..., -0.0337, -0.0334,  0.1494],\n",
      "          [-0.3184, -0.2236, -0.0016,  ..., -0.7422,  0.2168, -0.9102]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.1826,  0.3496, -0.1807,  ..., -0.0713, -0.8242,  0.4375],\n",
      "          [ 0.2158,  0.5430,  0.2451,  ...,  0.1865, -0.5742,  0.6875]],\n",
      "\n",
      "         [[-0.2930,  0.0108,  0.3906,  ..., -0.1187, -0.1621, -0.2051],\n",
      "          [ 0.0332, -0.4121,  0.4512,  ..., -0.2002, -0.2617, -0.3828]],\n",
      "\n",
      "         [[-0.4805, -0.4590, -1.0547,  ...,  0.3105, -0.0391,  0.2910],\n",
      "          [-0.4531, -0.9297, -0.5742,  ..., -0.2295, -0.4492,  0.8125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1279, -0.2949,  0.4570,  ...,  0.2012, -0.0386,  0.0143],\n",
      "          [-0.1147, -0.2031,  0.9453,  ...,  0.3145, -0.3457, -0.3730]],\n",
      "\n",
      "         [[-0.3926,  0.9648, -0.1030,  ..., -0.0452,  0.4648,  0.3027],\n",
      "          [ 0.1396,  1.1406,  0.0128,  ..., -0.5469,  0.2354,  0.2080]],\n",
      "\n",
      "         [[ 0.1328, -0.0442, -0.1807,  ..., -0.3438, -0.0732,  0.1914],\n",
      "          [ 0.5547,  0.3164, -0.7500,  ..., -0.4004, -0.1807,  0.3848]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0732,  0.0284, -0.0272,  ..., -0.0630, -0.0294,  0.0069],\n",
      "          [-0.3848,  0.6367, -0.3867,  ..., -0.2676,  1.1094, -0.5547]],\n",
      "\n",
      "         [[ 0.0150,  0.1230,  0.0272,  ..., -0.1260,  0.0161,  0.0073],\n",
      "          [-0.2188, -0.6094,  0.1562,  ..., -0.1279, -0.6562,  0.4473]],\n",
      "\n",
      "         [[-0.1924,  0.0835,  0.0698,  ..., -0.1553, -0.1221, -0.0059],\n",
      "          [-0.0136, -0.0908, -0.2061,  ..., -0.1582, -0.1196, -0.2559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0649, -0.0231, -0.2041,  ..., -0.0840, -0.2305,  0.0308],\n",
      "          [ 0.6133, -0.5469, -0.1992,  ..., -0.4492,  0.3301,  0.0503]],\n",
      "\n",
      "         [[-0.0723,  0.1309,  0.0476,  ..., -0.1289, -0.0018,  0.0041],\n",
      "          [ 0.7148, -0.2539, -0.2656,  ...,  0.7539,  0.4355, -0.1260]],\n",
      "\n",
      "         [[ 0.0137, -0.0479, -0.0245,  ...,  0.0098, -0.0708, -0.0425],\n",
      "          [-0.4043,  0.3711,  0.2432,  ..., -0.7930, -0.0214, -0.1504]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.3594, -0.3184, -0.0811,  ...,  0.1455, -1.0234,  0.2080],\n",
      "          [ 1.1562, -0.0928, -0.2197,  ...,  0.5312, -0.3223,  0.4277]],\n",
      "\n",
      "         [[-0.3457, -0.9453, -1.6953,  ..., -0.7812, -0.2695,  1.1562],\n",
      "          [-0.1875, -1.1641, -1.6250,  ..., -1.4453, -0.2373,  1.4141]],\n",
      "\n",
      "         [[-0.1523,  0.1865,  0.0688,  ...,  0.1719, -0.4883, -0.2539],\n",
      "          [-0.5078,  0.2217, -0.2520,  ...,  0.7266, -1.1641,  0.1191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0244, -0.7891, -0.3477,  ..., -0.9102,  0.2061,  0.3379],\n",
      "          [-0.0432, -1.4844, -0.6133,  ..., -1.1094, -0.1787,  0.7148]],\n",
      "\n",
      "         [[-1.1719, -0.8789, -0.0198,  ..., -0.0265,  0.2129, -0.3379],\n",
      "          [-1.6406, -0.7109,  0.0869,  ...,  0.2969,  0.3906, -0.5430]],\n",
      "\n",
      "         [[-0.1855, -0.2832,  0.5469,  ...,  0.1631,  0.2119, -0.3730],\n",
      "          [-0.3750, -0.6289,  0.9766,  ...,  0.2461,  0.0187, -0.5234]]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<PermuteBackward0>), tensor([[[[ 2.9907e-02,  3.2812e-01, -6.7234e-05,  ...,  3.6133e-02,\n",
      "            9.0942e-03,  1.5039e-01],\n",
      "          [ 6.7969e-01,  1.3594e+00,  3.6914e-01,  ..., -1.4844e-01,\n",
      "            2.2656e-01,  2.5391e-01]],\n",
      "\n",
      "         [[-2.9688e-01, -1.9824e-01, -1.4954e-03,  ..., -1.6406e-01,\n",
      "            1.0840e-01, -5.5908e-02],\n",
      "          [-6.2109e-01,  2.6562e-01,  5.0000e-01,  ..., -6.7578e-01,\n",
      "           -4.5312e-01,  1.2500e+00]],\n",
      "\n",
      "         [[-3.5938e-01, -2.7930e-01, -3.4424e-02,  ..., -6.5430e-02,\n",
      "            5.1025e-02,  2.3828e-01],\n",
      "          [-2.3560e-02, -8.5547e-01,  3.7695e-01,  ..., -7.8125e-01,\n",
      "            6.5234e-01, -7.0312e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5781e+00,  3.0781e+00,  3.0859e-01,  ..., -5.9375e-01,\n",
      "           -2.9062e+00, -9.1016e-01],\n",
      "          [-2.5156e+00, -2.3750e+00,  2.0996e-01,  ...,  2.0625e+00,\n",
      "            1.3203e+00, -3.2969e+00]],\n",
      "\n",
      "         [[ 5.5469e-01,  1.6309e-01, -3.8672e-01,  ...,  4.1406e-01,\n",
      "            1.9141e-01, -2.4170e-02],\n",
      "          [ 7.7734e-01,  1.6406e-01, -4.3359e-01,  ...,  1.0889e-01,\n",
      "            1.1768e-01, -6.8750e-01]],\n",
      "\n",
      "         [[-5.8838e-02,  4.6289e-01, -2.2266e-01,  ...,  3.5156e-02,\n",
      "           -2.6367e-01, -4.6387e-02],\n",
      "          [-7.8516e-01,  8.2031e-01,  3.7891e-01,  ..., -3.8867e-01,\n",
      "            3.4424e-02, -1.9043e-01]]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# get model predictions\n",
    "model_predictions = model(**tokenized_prompt)\n",
    "print(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n",
      "logits\n",
      "logits type: <class 'torch.Tensor'>\n",
      "logits size: torch.Size([1, 2, 50257])\n",
      "\n",
      "past_key_values\n",
      "past_key_values type: <class 'tuple'>\n",
      "past_key_values size: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### SOLUTION\n",
    "print(type(model_predictions))\n",
    "for key, value in model_predictions.items():\n",
    "    print(f\"{key}\")\n",
    "    print(f\"{key} type: {type(value)}\")\n",
    "    if hasattr(value, \"size\"):\n",
    "        # if the value has a size method, print its size\n",
    "        # this is the case for torch tensors\n",
    "        # if not, just print the value\n",
    "        print(f\"{key} size: {value.size()}\")\n",
    "    else:\n",
    "        print(f\"{key} size: {len(value)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_top_k_tokens(prompt, model_tokenizer, k=10):\n",
    "    \"\"\"\n",
    "    Returns top k tokens predicted by the given tuple of model-tokenizer and \n",
    "    given prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    # unpacking\n",
    "    model = model_tokenizer[MODEL]\n",
    "    tokenizer = model_tokenizer[TOKENIZER]\n",
    "\n",
    "    # tokenizer prompt\n",
    "    tokenized_prompt = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # forward pass\n",
    "    model_predictions = model(**tokenized_prompt)\n",
    "\n",
    "    # get top k tokens\n",
    "    top_10_tokens = None\n",
    "    \n",
    "    ### WRITE YOUR CODE HERE ###\n",
    "\n",
    "    # sort logits for sampling \n",
    "    _, sorted_indices = torch.sort(\n",
    "        F.softmax(model_predictions[\"logits\"][:, -1, :], dim=-1), \n",
    "        descending=True\n",
    "        )\n",
    "    sorted_indices = sorted_indices[0][:k]\n",
    "\n",
    "    # decode top k tokens\n",
    "    top_10_tokens = tokenizer.batch_decode(\n",
    "        sorted_indices,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return top_10_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', ' I', ' This', ' It', ' Is', ' Hello', ' You', ' My', ' Are']\n"
     ]
    }
   ],
   "source": [
    "# test your function\n",
    "prompt = \"Hello?\"\n",
    "top_10_tokens = get_top_k_tokens(prompt, models_dict[\"gpt3\"], k=10)\n",
    "print(top_10_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: gpt3\n",
      "PROMPT:\n",
      "What is the capital of France?\n",
      "TOP 10 TOKENS: ['\\n', ' The', ' What', ' It', ' How', ' Paris', ' A', ' Is', ' Where', ' I']\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "model_name = \"gpt3\"\n",
    "# model_name = \"llama\"\n",
    "\n",
    "# ask basic questions\n",
    "prompt = \"What is the capital of France?\"\n",
    "# prompt = \"What is the largest continent?\"\n",
    "# prompt = \"I have 30 apples, I eat 2, give away 6 and store 5 for the winter. How many apples do I have left?\"\n",
    "\n",
    "# get top tokens\n",
    "top_10_tokens = get_top_k_tokens(prompt, models_dict[model_name])\n",
    "\n",
    "print(\"MODEL:\", model_name)\n",
    "print(f\"PROMPT:\\n{prompt}\")\n",
    "print(\"TOP 10 TOKENS:\", top_10_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: gpt3\n",
      "PROMPT:\n",
      "Germany:Berlin. Italy:Rome. France:\n",
      "TOP 10 TOKENS: ['Paris', 'B', 'L', 'R', ' Paris', 'T', 'Mar', 'Le', 'N', 'Ber']\n"
     ]
    }
   ],
   "source": [
    "### SOLUTION\n",
    "model_name = \"gpt3\"\n",
    "# model_name = \"llama\"\n",
    "\n",
    "prompt = \"Germany:Berlin. Italy:Rome. France:\"\n",
    "# prompt = \"Germany:Berlin. France:Paris. Italy:\"\n",
    "# prompt = \"France:Paris. Italy:Rome. Germany:\"\n",
    "\n",
    "# get top tokens\n",
    "top_10_tokens = get_top_k_tokens(prompt, models_dict[model_name])\n",
    "\n",
    "print(\"MODEL:\", model_name)\n",
    "print(f\"PROMPT:\\n{prompt}\")\n",
    "print(\"TOP 10 TOKENS:\", top_10_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_demonstrations_world_capitals():\n",
    "    \"\"\"\n",
    "    Task: World capitals.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"Portugal\",\n",
    "        \"Germany\",\n",
    "        \"Italy\",\n",
    "        \"Spain\",\n",
    "        \"Poland\",\n",
    "        \"France\",\n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"Lisbon\",\n",
    "        \"Berlin\",\n",
    "        \"Rome\",\n",
    "        \"Madrid\",\n",
    "        \"Warsaw\",\n",
    "        \"Paris\",\n",
    "    ]\n",
    "\n",
    "    return questions, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demonstrations_verb_declination():\n",
    "    \"\"\"\n",
    "    Task: Verb declination in English.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"I go, he \",\n",
    "        \"I play, he \",\n",
    "        \"I eat, he \",\n",
    "        \"You swim, she \",\n",
    "        \"You sleep, she \",\n",
    "        \"You sing, she \",\n",
    "        \"We say, she \",\n",
    "        \"We study, she \",\n",
    "        \"We pay, she \",\n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"goes\",\n",
    "        \"plays\",\n",
    "        \"eats\",\n",
    "        \"swims\",\n",
    "        \"sleeps\",\n",
    "        \"sings\",\n",
    "        \"says\",\n",
    "        \"studies\",\n",
    "        \"pays\",\n",
    "    ]\n",
    "\n",
    "    return questions, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demonstrations_ioi():\n",
    "    \"\"\"\n",
    "    Task: indirect object identification.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"When Mary and John went to the store, John gave a drink to \", \n",
    "        \"Alice and Bob were playing chess. Alice won the game against \",\n",
    "        \"Harry and Hermione were studing in the library. Harry passed the book to \",\n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"Mary\",\n",
    "        \"Bob\",\n",
    "        \"Hermione\",\n",
    "    ]\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demonstrations_translate_to_french():\n",
    "    \"\"\"\n",
    "    Task: translate to French.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"Car\",\n",
    "        \"House\",\n",
    "        \"Dog\",\n",
    "        \"Cat\", \n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"Voiture\",\n",
    "        \"Maison\",\n",
    "        \"Chien\",\n",
    "        \"Chat\",\n",
    "    ]\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demonstrations_translate_to_german():\n",
    "    \"\"\"\n",
    "    Task: translate to German.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"Car\",\n",
    "        \"House\",\n",
    "        \"Dog\",\n",
    "        \"Cat\",\n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"Auto\",\n",
    "        \"Haus\",\n",
    "        \"Hund\",\n",
    "        \"Katze\",\n",
    "    ]\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demonstrations_translate_to_spanish():\n",
    "    \"\"\"\n",
    "    Task: translate to Spanish.\n",
    "    \"\"\"\n",
    "\n",
    "    questions = [\n",
    "        \"Car\"\n",
    "        \"House\"\n",
    "        \"Dog\"\n",
    "        \"Cat\",\n",
    "    ]\n",
    "\n",
    "    answers = [\n",
    "        \"Automovil\",\n",
    "        \"Casa\",\n",
    "        \"Perro\",\n",
    "        \"Gato\",\n",
    "    ]\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_icl_prompt(\n",
    "        questions, \n",
    "        answers, \n",
    "        qa_template,\n",
    "        instruction=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Constructs an in-context learning (ICL) prompt.\n",
    "\n",
    "    Args:\n",
    "        questions (list): List of questions, all but the last will be used\n",
    "            as demonstrations in the prompt, whereas the last one will be\n",
    "            the question to be answered.\n",
    "        answers (list): corresponding answers to given set of questions.\n",
    "        instruction (str): Instruction to be used in the prompt.\n",
    "        qa_template (bool): If True, demonstrations are of the form \n",
    "                            Q: <question>. A: <answer>. If False, demonstrations \n",
    "                            are of the form <question>:<answer>. \n",
    "    Returns:\n",
    "        str: ICL prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\n",
    "    if instruction is not None:\n",
    "        prompt = instruction + \"\\n\\n\"\n",
    "    if qa_template:\n",
    "        for i, question in enumerate(questions[:-1]):\n",
    "            prompt += f\"Q: {question}\\nA: {answers[i]}\\n\\n\"\n",
    "        prompt += f\"Q: {questions[-1]}\\nA:\"\n",
    "    else:\n",
    "        for i, question in enumerate(questions[:-1]):\n",
    "            prompt += f\"{question}:{answers[i]}\\n\"\n",
    "        prompt += f\"{questions[-1]}:\"\n",
    "\n",
    "    return prompt, answers[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use this function to sample and shuffle demonstrations\n",
    "def sample_and_shuffle_demonstrations(questions, answers, num_demos):\n",
    "    if num_demos > len(questions):\n",
    "        raise ValueError(\n",
    "            f\"Number of demonstrations ({num_demos}) is greater than the number of questions ({len(questions)})\"\n",
    "        )\n",
    "    sampled_questions = []\n",
    "    sampled_answers = []\n",
    "    for i in range(num_demos):\n",
    "        sampled_index = random.randint(0, len(questions) - 1)\n",
    "        sampled_questions.append(questions[sampled_index])\n",
    "        sampled_answers.append(answers[sampled_index])\n",
    "        questions.pop(sampled_index)\n",
    "        answers.pop(sampled_index)\n",
    "\n",
    "    return sampled_questions, sampled_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: We study, she \n",
      "A: studies\n",
      "\n",
      "Q: I play, he \n",
      "A:\n",
      "\n",
      "ANSWER: plays\n"
     ]
    }
   ],
   "source": [
    "# test ICL prompts\n",
    "num_demos = 2\n",
    "questions, answers = get_demonstrations_verb_declination()\n",
    "questions, answers = sample_and_shuffle_demonstrations(\n",
    "    questions, answers, num_demos\n",
    ")\n",
    "icl_prompt, answer = construct_icl_prompt(\n",
    "    questions, \n",
    "    answers,\n",
    "    qa_template=True \n",
    ")\n",
    "print(icl_prompt)\n",
    "print(\"\\nANSWER:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: gpt3\n",
      "PROMPT:\n",
      "Italy:\n",
      "ANSWER: Rome\n",
      "TOP 10 TOKENS: [' The', ' the', ' A', '\\n', ' a', ' ', \" '\", ' Un', ' \"', ' ']\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "model_name = \"gpt3\"\n",
    "num_demos = 1\n",
    "qa_template=False\n",
    "questions, answers = get_demonstrations_world_capitals()\n",
    "\n",
    "# construct ICL prompt\n",
    "questions, answers = sample_and_shuffle_demonstrations(\n",
    "    questions, answers, num_demos\n",
    ")\n",
    "icl_prompt, answer = construct_icl_prompt(\n",
    "    questions, \n",
    "    answers, \n",
    "    qa_template=qa_template,\n",
    ")\n",
    "\n",
    "# get model predictions\n",
    "top_10_tokens = get_top_k_tokens(icl_prompt, models_dict[model_name])\n",
    "\n",
    "# inspect results\n",
    "print(\"MODEL:\", model_name)\n",
    "print(f\"PROMPT:\\n{icl_prompt}\")\n",
    "print(\"ANSWER:\", answer)\n",
    "print(\"TOP 10 TOKENS:\", top_10_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: llama\n",
      "PROMPT:\n",
      "Translate the following word to french.\n",
      "\n",
      "Portugal:\n",
      "ANSWER: Lisbon\n",
      "TOP 10 TOKENS: [' ', '\\xa0', ' (', ' Portugal', ' a', ' A', ' the', ' port', ' The', ' Portuguese']\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "# model_name = \"gpt3\"\n",
    "model_name = \"llama\"\n",
    "num_demos = 1\n",
    "qa=False\n",
    "instruction=\"Translate the following word to french.\"\n",
    "questions, answers = get_demonstrations_world_capitals()\n",
    "\n",
    "# construct ICL prompt\n",
    "questions, answers = sample_and_shuffle_demonstrations(\n",
    "    questions, answers, num_demos\n",
    ")\n",
    "icl_prompt, answer = construct_icl_prompt(\n",
    "    questions, \n",
    "    answers, \n",
    "    qa_template=qa,\n",
    "    instruction=instruction\n",
    ")\n",
    "\n",
    "# get model predictions\n",
    "top_10_tokens = get_top_k_tokens(icl_prompt, models_dict[model_name])\n",
    "\n",
    "# inspect results\n",
    "print(\"MODEL:\", model_name)\n",
    "print(f\"PROMPT:\\n{icl_prompt}\")\n",
    "print(\"ANSWER:\", answer)\n",
    "print(\"TOP 10 TOKENS:\", top_10_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load Llama-3.2-1B-Instruct \n",
    "llama_instruct_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "models_dict[\"llama_instruct\"].append(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        llama_instruct_name, \n",
    "        device_map=DEVICE, \n",
    "        torch_dtype=torch.bfloat16, \n",
    "    )\n",
    ")\n",
    "models_dict[\"llama_instruct\"].append(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        llama_instruct_name, padding_side=\"left\"\n",
    "        )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: llama_instruct\n",
      "PROMPT:\n",
      "Translate the following word to French.\n",
      "\n",
      "Q: House\n",
      "A:\n",
      "ANSWER: Maison\n",
      "TOP 10 TOKENS: [' Maison', ' M', ' Ch', ' La', ' maison', ' Mais', ' Man', ' Le', ' Case', ' C']\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "# model_name = \"gpt3\"\n",
    "# model_name = \"llama\"\n",
    "model_name = \"llama_instruct\"\n",
    "num_demos = 1\n",
    "qa=True\n",
    "instruction=\"Translate the following word to French.\"\n",
    "questions, answers = get_demonstrations_translate_to_french()\n",
    "\n",
    "# construct ICL prompt\n",
    "questions, answers = sample_and_shuffle_demonstrations(\n",
    "    questions, answers, num_demos\n",
    ")\n",
    "icl_prompt, answer = construct_icl_prompt(\n",
    "    questions, \n",
    "    answers, \n",
    "    qa_template=qa,\n",
    "    instruction=instruction\n",
    ")\n",
    "\n",
    "# get model predictions\n",
    "top_10_tokens = get_top_k_tokens(icl_prompt, models_dict[model_name])\n",
    "\n",
    "# inspect results\n",
    "print(\"MODEL:\", model_name)\n",
    "print(f\"PROMPT:\\n{icl_prompt}\")\n",
    "print(\"ANSWER:\", answer)\n",
    "print(\"TOP 10 TOKENS:\", top_10_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Longer Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(\n",
    "        prompt, \n",
    "        model_tokenizer, \n",
    "        num_tokens=10,\n",
    "        verbose=False,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Returns string constructed with sequence of num_tokens tokens predicted by\n",
    "    given model using greedy decoding on given prompt.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        Prompt to be used for generation.\n",
    "    model_tokenizer : tuple\n",
    "        Tuple of model and tokenizer\n",
    "    num_tokens : int\n",
    "        Number of tokens to be generated.\n",
    "    num_tokens : bool\n",
    "        Flag for printing tokens as they are generated.\n",
    "    \"\"\"\n",
    "\n",
    "    # unpacking\n",
    "    model = model_tokenizer[MODEL]\n",
    "    tokenizer = model_tokenizer[TOKENIZER]\n",
    "\n",
    "    final_str = \"\"\n",
    "    ### WRITE YOUR CODE HERE ### \n",
    "\n",
    "    for i in range(num_tokens):\n",
    "\n",
    "        # tokenize prompt\n",
    "        tokenized_prompt = tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # get model predictions\n",
    "        model_predictions = model(**tokenized_prompt)\n",
    "\n",
    "        # sort logits for sampling \n",
    "        _, sorted_indices = torch.sort(\n",
    "            F.softmax(model_predictions[\"logits\"][:, -1, :], dim=-1), \n",
    "            descending=True\n",
    "            )\n",
    "        \n",
    "        # sorted_indices is of size (batch_size, vocab size)\n",
    "        sorted_indices = sorted_indices[0]\n",
    "\n",
    "        # add top k to output\n",
    "        top_token = tokenizer.batch_decode(\n",
    "            sorted_indices[:1],\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        # add predicted token to final string and to prompt\n",
    "        final_str += top_token\n",
    "        prompt += top_token\n",
    "        \n",
    "        if verbose:\n",
    "            print(top_token)\n",
    "\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED TEXT:  I'm a newbie to the forum and I\n"
     ]
    }
   ],
   "source": [
    "# test your function\n",
    "prompt = \"Hello! \"\n",
    "model_name = \"gpt3\"\n",
    "# generate text\n",
    "generated_text = generate(\n",
    "    prompt, \n",
    "    models_dict[model_name], \n",
    ")\n",
    "print(\"GENERATED TEXT:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED STR:\n",
      "\n",
      " Paris.\n",
      "The capital of France is Paris. Paris is the most populous city in France and is known\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "model_name = \"llama_instruct\"\n",
    "num_tokens = 20\n",
    "\n",
    "# set prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "# generate answer\n",
    "generated_str = generate(\n",
    "    prompt, \n",
    "    models_dict[model_name], \n",
    "    num_tokens,\n",
    ")\n",
    "print(\"GENERATED STR:\\n\")\n",
    "print(generated_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUTPUT:\n",
      "\n",
      "What is the capital of France? Paris.\n",
      "The capital of France is Paris. This\n"
     ]
    }
   ],
   "source": [
    "# settings \n",
    "model_name = \"llama_instruct\"\n",
    "num_tokens = 10\n",
    "\n",
    "# set prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "# unpack model and tokenizer\n",
    "model = models_dict[model_name][MODEL]\n",
    "tokenizer = models_dict[model_name][TOKENIZER]\n",
    "\n",
    "# we need to tokenize the prompt ourselves\n",
    "tokenized_prompt = tokenizer(\n",
    "    prompt, \n",
    "    return_tensors=\"pt\"\n",
    ").to(DEVICE)\n",
    "\n",
    "# generate answer with model's generate function\n",
    "generated_ids = model.generate(\n",
    "    **tokenized_prompt,\n",
    "    max_new_tokens=num_tokens,\n",
    "    )\n",
    "\n",
    "# inspect results\n",
    "# note this output already includes the prompt\n",
    "print(\"\\nOUTPUT:\\n\")\n",
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to construct chat history\n",
    "def construct_chat_prompt(\n",
    "        new_prompt: str, \n",
    "        chat_history: str = \"\", \n",
    "        system_prompt: str = None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Constructs prompt for chatting with model. \n",
    "\n",
    "    Args:\n",
    "        new_prompt (str): new user entry in conversation\n",
    "        chat_history (str): all of the conversation so far\n",
    "        system_prompt (str): system prompt to give model initial instructions\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\n",
    "    if system_prompt is not None:\n",
    "        prompt = f\"{system_prompt}\\n\\n\"\n",
    "\n",
    "    return prompt + chat_history + new_prompt + \"\\n\\n<ASSISTANT>\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUTPUT:\n",
      "\n",
      "You are a helpful assistant. You will answer the user's questions in a friendly and informative manner.\" \n",
      "\n",
      "<USER>\n",
      "\n",
      "Hello? Who are you?\n",
      "\n",
      "<ASSISTANT>\n",
      "\n",
      "I'm an AI assistant, here to help answer any questions you may have. I'm here to\n"
     ]
    }
   ],
   "source": [
    "# settings \n",
    "model_name = \"llama_instruct\"\n",
    "num_tokens = 20\n",
    "\n",
    "# set up a system prompt\n",
    "system_prompt = \"\"\"You are a helpful assistant. You will answer the user's questions in a friendly and informative manner.\" \n",
    "\n",
    "<USER>\"\"\"\n",
    "\n",
    "# set up new dialogue entry\n",
    "dialogue_entry = \"Hello? Who are you?\"\n",
    "\n",
    "# construct chat prompt\n",
    "prompt = construct_chat_prompt(\n",
    "    new_prompt=dialogue_entry, \n",
    "    chat_history=\"\", \n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "# unpack\n",
    "model = models_dict[model_name][MODEL]\n",
    "tokenizer = models_dict[model_name][TOKENIZER]\n",
    "\n",
    "# we need to tokenize the prompt ourselves\n",
    "tokenized_prompt = tokenizer(\n",
    "    prompt, \n",
    "    return_tensors=\"pt\"\n",
    ").to(DEVICE)\n",
    "\n",
    "# generate model response\n",
    "generated_ids = model.generate(\n",
    "    **tokenized_prompt,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=num_tokens,\n",
    "    )\n",
    "\n",
    "# inspect results\n",
    "# note this output already includes the prompt\n",
    "print(\"\\nOUTPUT:\\n\")\n",
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
